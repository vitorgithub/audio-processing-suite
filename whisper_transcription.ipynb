{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX5uP_7nxtCp",
        "outputId": "1a732352-9559-47e0-df2a-97b8400a99d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting openai-whisper\n",
            "  Downloading openai-whisper-20230918.tar.gz (794 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.3/794.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.23.5)\n",
            "Collecting torch (from openai-whisper)\n",
            "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m246.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.1.0)\n",
            "Requirement already satisfied: tiktoken==0.3.3 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.3.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper) (2.31.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.27.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.12.4)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (17.0.3)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m195.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m408.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m182.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m262.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m302.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m206.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m289.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m236.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m239.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m164.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m198.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch (from openai-whisper)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m174.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.91)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper) (0.41.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230918-py3-none-any.whl size=798399 sha256=dfec5a98c5008bd8c911013af08469b2127d4d560bc79231b10e5d071c7482f7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cwtkcvns/wheels/5d/37/b1/9aea93201fe91e3561719120da92cc23e77b7ef6f3d0d9491a\n",
            "Successfully built openai-whisper\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: torch, openai-whisper\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-whisper-20230918 torch-2.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install openai-whisper --no-cache-dir\n",
        "import os\n",
        "import torch\n",
        "import whisper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transcrever_audio(model, file_name):\n",
        "    \"\"\"Transcreve o áudio usando o modelo Whisper.\"\"\"\n",
        "    result = model.transcribe(file_name, language=\"Portuguese\")\n",
        "    return result[\"text\"]\n",
        "\n",
        "def main():\n",
        "    # Carregar o modelo uma vez\n",
        "    model = whisper.load_model(\"large\")\n",
        "\n",
        "    # Lista dos nomes dos arquivos de audio\n",
        "    files = [\n",
        "    \"substitua esse array de strings pelo array fornecido pelo FilesToArray.exe\",\n",
        "    \"lembre-se de identar o código corretamente (04 espaços em branco)\"\n",
        "\"não faça desse jeito que eu fiz nessa linha.\"\n",
        "    ]\n",
        "\n",
        "    for file_path in files:\n",
        "        try:\n",
        "            transcription = transcrever_audio(model, file_path)  # Passar o modelo como argumento\n",
        "            print(f\"Transcrição para o arquivo '{file_path}':\\n{transcription}\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao processar o arquivo '{file_path}': {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfIXGXk2x3Pn",
        "outputId": "b59bb7d4-3f66-48ed-a535-acdd29822dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.87G/2.87G [01:35<00:00, 32.2MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcrição para o arquivo './sample_data/AZ-900 EP 1-5 AZ900 Treinamento Oficial Microsoft Azure Fundamentals.mp3':\n",
            " Olá, tudo bem com você? Eu sou Valeria Baptista e você está assistindo ao primeiro episódio do Movimento Oficial Microsoft da certificação AZ-900. Eu vou fazer um overview completo sobre todos os tópicos que abordam na prova, vamos fazer vários laboratórios a fim de levar você a garantir o seu PES nesta certificação. Deixe seus comentários neste vídeo, se inscreva no canal e fique por dentro de todas as novidades. Então vamos para a nossa primeira aula! Antes de mais nada, falando um pouquinho sobre a minha carreira pessoal, eu tenho um pouco mais de 10 anos de experiência em tecnologia, sou formada em ciências da computação e tenho pós em cloud computing. Atualmente sou MCT Microsoft e tenho várias certificações no campo de cloud, principalmente focado em Azure e também AWS. Minha missão é levar você a conseguir alcançar o desenvolvimento necessário, não apenas para sua prova, mas também para o dia a dia, iniciando aí na parte de administração de nuvem Azure. Então falando sobre a nossa prova pessoal, esse teste AZ-900, ela atualmente é 45 minutos o tempo do seu teste e aqui a gente traz alguns tópicos divulgados pela Microsoft, que são aqueles que são abordados na prova. Então a gente tem a possibilidade de escrever conceitos de nuvem, que é o tópico atualmente que tem maior peso, a gente precisa focar bastante, você não pode ficar com dúvidas sobre esses conceitos. Depois a gente vai falar um pouco sobre os principais serviços do Azure, as soluções e ferramentas de gerenciamento, depois vamos falar um pouco sobre os recursos gerais de segurança, identidade, governança e finalizamos com gerenciamento de custos e também contratos de nível de serviço. Esse é o nosso episódio 1, vamos falar sobre conceitos de nuvem. Nesse episódio nós temos três módulos, modelos de nuvem, considerações e benefícios da nuvem e os serviços de nuvem. Vamos começar com modelos de nuvem. Então primeiramente nós precisamos discutir o que é de fato computação em nuvem. Perceba pessoal que aqui a gente não está falando necessariamente de Azure, de AWS, de Google Cloud, entre outros providers de mercado que são bastante conhecidos, nós estamos falando do conceito inicial de computação em nuvem. Para quem vem da área de infraestrutura, como eu até, a gente geralmente tinha o seguinte contexto, você quando precisava expandir o seu poder computacional do seu data center, era necessário que a sua empresa fizesse alguns orçamentos, geralmente a gente fazia três orçamentos com empresas diferentes, encomendava ali os servidores, às vezes switch, rack, até mesmo o firewall, entre outros equipamentos, aguardava que esses equipamentos chegassem, depois ia lá, configurava, tudo isso levava um tempo, às vezes precisava de apoio de empresas terceiras e após isso é que podia se disponibilizar aquele serviço diferente para os setores, ou daqui a pouco para um projeto, entre outros. Perceba que falando de computação em nuvem, nós não temos mais essa dinâmica de ter que ficar fazendo orçamento, de esperar um x-tempo, até que aquele recurso computacional esteja disponível para nossa utilização. Trário, agora a gente acessa o portal, você tem a conta da empresa, onde você seleciona qual que é o recurso que você quer, se é de computação, se é um banco de dados, se é um modelo de container, kubernetes, todos esses estilos, né, esses sabores, digamos assim, que a gente fala, tem em todos os providers, então o que é a computação em nuvem em si, tirando o rótulo, tirando o nome de um provedor. Quando a gente fala de computação em nuvem, nós estamos falando daquela entrega de serviços, o self-service, onde você tem uma conta, um cadastro em um provider, você tem acesso por um portal, que seria estilo um e-commerce, por exemplo, você tem a conta em uma loja, conhecida ou não, mas você acessa aquele e-commerce e tem lá, se você quer comprar um roupeiro, se você quer comprar uma geladeira, você quer comprar um jogo de talher, independente, ou daqui a pouco uma ferramenta, aqui nós temos o mesmo modelo de ambiente, só que o nosso e-commerce é de recursos computacionais, e perceba que uma conta, trial, por exemplo, que vai ter um X tempo de utilização, ela vai enxergar os mesmos recursos computacionais que outra conta enxergaria, de uma grande empresa, que tem um grande contato, às vezes, até diretamente com o provider, se ela vai poder adquirir uma coisa, mas ela tem o acesso, então a computação em nuvem nada mais é do que a entrega rápida de recursos computacionais que estão em um determinado provider, quais recursos, aqueles que eu tiver condições de adquirir. E outra coisa, a gente vai falar mais adiante sobre os modelos de pagamento, mas uma coisa que fica bem clara aqui, é que quando nós trabalhamos no modelo on-premise, você precisa adquirir, ou seja, você paga na frente por aquele recurso, aguarda que ele chegue, faz a configuração, isso é tudo sua responsabilidade, e depois você disponibiliza internamente. Dentro desse modelo de computação em nuvem, você vai escolher aquilo que você precisa utilizar, vai utilizar por 30 dias e somente depois disso que você vai pagar, lembrando, pagando por aquilo que você utilizou, ou seja, se eu criar uma máquina hoje, utilizar ela por uma semana, eu não vou pagar todo o valor de 30 dias, por exemplo, eu vou pagar somente dos dias que ela ficou ligada. Então você vai ter acesso ao recurso e vai pagar apenas pelo uso, isso é uma das grandes vantagens, o fato de você poder disponibilizar um ambiente com altos recursos computacionais, de uma forma quase que automática, para a sua empresa dentro, atingindo a sua necessidade, aquilo que você precisa, isso faz com que as empresas consigam expandir muito mais rápido, perceba que a computação em nuvem fornece para nós possibilidades que o modelo on-premise não conseguiria atingir, mas falando no modelo, nós temos três modelos aqui que nós vamos discutir, o primeiro deles vai ser um modelo de nuvem pública, aqui nós estamos falando dos providers em si, ou seja, quando nós falamos de uma nuvem pública, a gente pode estar discutindo aqui o modelo do Azure, do AWS, do GCP, do Oracle Cloud, aqui nós temos um provider, ou provedor, que ele nos oferta recursos, é claro que cada provider vai ter um nome para aquele recurso, ele vai cobrar um valor específico, mas o recurso está ali, nós vamos escolher de onde nós vamos adquirir esse recurso, mas lembrando que a nuvem pública, ela vai nos fornecer acesso, não apenas a nós, mas a todo aquele que tiver um cadastro, e a partir daí todos podem consumir os recursos daquela nuvem, ou seja, se você criar hoje uma conta trial na Azure, aquela que vale por 30 dias, e fizer o seu acesso num servidor, por exemplo, localizado na região do Brasil, criar uma máquina lá, perceba que aonde você está criando uma máquina, no servidor físico onde essa máquina virtualizada vai ser criada, pode ter do ladinho, digamos assim, um servidor de uma grande empresa, então vocês estão consumindo recursos da mesma fonte, não é um data center para contas que são 30 dias, um data center para o cliente que veio por um CSP, por exemplo, ou um data center para um modelo que veio diretamente de um contrato com a Microsoft que nós chamamos de Enterprise Agreement, então todos nós vamos consumir os recursos naquela mesma fonte, nós temos acesso, o mesmo painel, ele não é diferenciado pelo seu modelo de conta, muito pelo contrário, nós vamos enxergar os recursos ali da mesma forma e vamos acessar esses recursos pela internet, é claro que uma empresa hoje, ela pode fazer uma conexão de VPN site to site, point to site, ou até mesmo express route, nós vamos avaliar esses três modelos mais adiante, mas é interessante a gente entender que a nuvem pública, independente do provider, ela vai nos oferecer o acesso a esses recursos independente do nosso modelo de contrato e não vai fazer uma distinção de aonde vai colocar esses recursos, nós que vamos estipular qual a localidade, mas não tem um data center para um cliente X, um data center para o cliente Y, não, todos nós consumimos os recursos de uma mesma fonte. Quando nós falamos da nuvem privada, aqui a gente está falando literalmente de como era o nosso ambiente on-premise, porque aqui quando nós começamos a falar de virtualização, de serviços de nuvem, nós estamos falando de uma nuvem aonde o próprio ambiente, a empresa, ela vai criar um ambiente virtualizado para si, mas isso não é aberto a outras fontes, ou seja, o acesso vai ser somente para pessoas de dentro daquela organização. Perceba que na nuvem pública, todos acessamos a nuvem da Ager, da AWS e por aí vai. Quando nós falamos da nuvem privada, nós vamos ter o acesso somente dentro daquele data center, aquela nuvem é somente daquela empresa, ela não está aberta a ser consumida por outras empresas, então nós estamos falando de uma nuvem que vai funcionar literalmente apenas dentro daquela empresa sem acesso para pessoas de fora. E o nosso último modelo, que é a nuvem híbrida, eu costumo dizer que a nuvem híbrida é o melhor dos dois mundos, aonde nós mantemos alguns recursos computacionais, nosso ambiente on-premise dentro de casa e também utilizamos a nuvem pública para adquirir serviços dentro deste modelo self-service e a partir daí aproveitar recursos computacionais que seriam muito caros para ser adquiridos e não teríamos acesso dentro de uma empresa normal. Então a partir deste momento você tem uma comunicação do seu ambiente on-premise, da sua nuvem privada para a nuvem pública e aqui você consegue trafegar informações entre as duas. O modelo de nuvem híbrida atualmente ainda é o mais utilizado e acredito que vai perdurar por mais algum tempo, porque hoje empresas para começarem na nuvem geralmente são startups, são empresas que estão iniciando agora, então não vale a pena construir um ambiente de data center, isso se torna muito caro, às vezes complexo demais, as empresas não iniciam com muitas pessoas, então se torna muito mais prático iniciar a jornada já na nuvem pública. Porém empresas mais antigas que já tem toda uma história, estão há bastante tempo no mercado, já possuíam vários data centers, às vezes até dentro de operadoras, não faz sentido a empresa às vezes ter contrato, não pode se livrar desses equipamentos por si só, ou até mesmo tem muitos que foram comprados há pouco tempo, estão em pleno uso e um caso bastante conhecido são os ambientes de legado também, onde quando a gente pensa em ir para a nuvem e levar tudo para a nuvem, não é tão fácil assim, nós vamos falar sobre isso ao longo do curso, mas é importante você entender que existem muitos ambientes que contêm sistemas muito antigos e para o modelo de nuvem eles não estão preparados, então por isso que a gente tem todo esse movimento de nuvem híbrida hoje, porque se torna mais prático você ir levando os recursos aos poucos e assim ir literalmente desmembrando o que você tem dentro de casa, mas não abre mão de ir crescendo na nuvem e adquirindo novos recursos computacionais falando da nuvem pública, então quando nós falamos da nuvem pública nós estamos falando 100% nuvem, a nuvem privada é aquela dentro da nossa empresa e a híbrida é quando nós temos um pouco dos dois. E vamos falar aqui sobre os conceitos e também fazer um comparativo desses três modelos de nuvem, é um item que cai bastante em prova pessoal, então você não pode ter dúvidas com relação a quais são as características desses três modelos. Então falando inicialmente sobre a nuvem pública, aqui nós até mencionamos que nenhuma despesa de capital para escalar verticalmente, o que seria essa despesa de capital? Lembra que eu comentei que antigamente, ou até mesmo hoje quem usa ainda modelo on-premise, se você vai adquirir um recurso computacional, até mesmo switch, fire ou máquinas, você paga na frente, isso é uma despesa de capital. Quando a gente fala de nuvem pública, nós estamos falando de uma despesa operacional, por quê? Porque você vai usar aquele recurso e após 30 dias, lembra do seu cartão de crédito, depois de 30 dias você vai pagar por aquilo que você utilizou. E também nós temos esse modelo self-service, onde através de um portal, nós vamos literalmente adquirir os recursos que a gente quer. Claro que quem já trabalha com isso sabe que nós podemos utilizar também ferramentas de automação, automatização, infraestrutura como código, um terraform, Azure Bicep, mas a gente sabe que nós temos um portal, pense o portal do Azure como um e-commerce de uma loja, ali você tem o seu cadastro, você acessa, só que pense que nada você vai comprar com boleto ou Pix, é tudo no cartão de crédito, seria mais ou menos assim porque você vai pagar após 30 dias e pagar apenas por aquilo que você utilizar. Se você provisionar um recurso, dali 5 minutos você ir ali excluir, você vai pagar somente pelo tempo que ele ficou disponível para você. Quando a gente fala da nuvem privada, nós estamos falando do modelo on-premise, onde toda a responsabilidade pela utilização, administração, configuração, é tudo sua responsabilidade. Ou seja, você fez a compra, chegou o equipamento, você tem que arrumar o rack, tem que passar cabo, tem que configurar o firewall, tudo é responsabilidade da TI interna. Quando a gente fala da nuvem pública, essa parte de hardware não é nossa responsabilidade, nós nem sabemos o endereço certo onde fica os data centers dos providers, por compliance eles não divulgam, divulgam no máximo a cidade, mas não o endereço, a gente não pode mandar um postal para lá. Então, nós temos dentro desse modelo, falando de nuvem privada, que tudo é nossa responsabilidade e a nuvem privada não pode ser acessada para subir recursos por outras empresas, ela é exclusiva da nossa empresa. E a nuvem híbrida será o melhor dos dois mundos, você tem ali seus dispositivos, no seu data center, mas você tem também uma comunicação, tem um cadastro para um data center de um provider, onde ali você vai ter acesso, vai criar seus recursos, subir seus serviços, máquinas, servidores e tudo mais. Então, aqui nós vamos ter um modelo aonde existe uma parte que é responsabilidade do provider, uma outra que é nossa responsabilidade, vamos pontuar isso também para que fique bem claro, mas é interessante que você saiba que a nuvem pública é aquela que nos dá maior flexibilidade. A Microsoft pode perguntar para você qual seria o melhor modelo de adoção, ou até mesmo dizendo se você precisa ter o seu ambiente somente dentro de casa, qual seria esse modelo, o ambiente on-premises, você vai ter a nuvem privada. Se você quer manter recursos no seu ambiente on-premises e utilizar a nuvem, que modelo é indicado que você use? É o modelo de nuvem híbrida. Então, você precisa ter bem em mente o que esses três modelos vão lhe ofertar para que quando na prova a Microsoft lhe perguntar isso, fique bem claro, você não tenha dúvidas. Lembrando que ao final de todas as nossas aulas a gente vai fazer um quiz para ajudar você a entender como que é formular essas perguntas e assim não ter sustos no seu teste. Vamos iniciar então o nosso módulo 2, falando sobre considerações e benefícios da nuvem. Então, vamos falar um pouco sobre os benefícios da nuvem. Primeiramente, começando por alta disponibilidade. Quando a gente fala de alta disponibilidade, ela está associada ao tempo que o nosso provider nos garante que um serviço vai estar disponível. Porque perceba que nós estamos comprando aqueles serviços dentro de um determinado data center ou realizando modelos de replicação dentro de uma região ou mais. Então, aquele provider, falando de benefícios de nuvem, não rotulando AWS, Azure, IGCP, entre outros, nós estamos falando do Service Level Agreement, ou seja, SLA, o acordo de nível de serviço. Então, aqui nós vamos ter um tempo que o provider garante para nós que aquele serviço vai estar disponível. Lembrando que isso é um contrato, não é apenas uma promessa. Se aquele item, por acaso, ficar indisponível por mais tempo do que aquilo que consta no acordo de SLA, nós vamos ter um reembolso de créditos na nossa conta. Então, assim, a Microsoft, por exemplo, nos garante que se nós estamos utilizando o Azure, nós estamos utilizando um serviço que tem uma disponibilidade X, se aquele serviço ficar indisponível por mais tempo, nós vamos ser reembolsados. Depois, na próxima fatura. Quando nós falamos do modelo de tolerância a falhas, em que tem um outro contexto, e às vezes o pessoal confunde um pouco com recuperação de desastre. O que acontece? Tolerância a falhas está muito associada à replicação de informações, porque quando eu tenho um modelo de tolerância a falhas no meu ambiente, eu garanto que, ainda que o meu serviço ficar indisponível em uma ponta, digamos assim, eu ainda vou ter ele funcionando. Ou seja, o meu usuário não percebe que aquele serviço está fora. Isso não é replicado para o meu cliente, por exemplo. Um modelo bastante utilizado, para a gente entender, quando nós falamos de uma região, da Azure, por exemplo, ela conta com pelo menos três datacenters. Se eu coloco um modelo de serviço que ele replica entre esses três datacenters, e por ventura um deles ficar fora, meu usuário não vai sentir esse problema, porque ainda está disponível nos dois. Se dois estiverem fora, ele vai continuar funcionando neste um datacenter que ficou funcionando. Ou seja, eu tenho um problema com meus recursos, digamos assim, eu tenho itens que estão fora, mas o meu usuário não percebe, porque o meu sistema não ficou indisponível. Ou seja, ele é tolerante a falhas. Então, isso está muito associado à questão de replicação dentro de uma região, ou até mesmo para regiões pares, que a gente vai falar sobre isso depois. A parte de escalabilidade e elasticidade, às vezes, também gera um pouco de confusão, mas pense na seguinte forma. Escalabilidade está associada quando a gente vai alterar recursos para atender uma demanda computacional. Ou seja, meu recurso vai ser escalável. Se eu tiver um servidor que tem um único disco a mais, e esse disco tem hoje, sei lá, 100 gigas, e ele está com uso em 95, eu posso ir lá e adicionar um outro disco ou aumentar o tamanho desse disco. Ou seja, eu vou estar aumentando o recurso computacional devido a uma necessidade, mas eu continuo com o mesmo modelo de máquina, eu não troquei memória, não troquei processador, eu aumentei o disco. Ou eu troquei a família de uma máquina, porque aquela que ela foi inicialmente não estava mais atendendo as necessidades. Eu estou alterando para um novo estado, ao qual eu não vou reverter, e ele não vai ficar alterando por conta. Eu só ajustei, readequei aquele recurso a uma nova necessidade. E isso é um novo benefício da nuvem também. Isso é escalabilidade. Quando falarem de escalabilidade, sempre lembre de algo escalável, você está subindo um recurso computacional. Quando a gente fala de elasticidade, lembre-se do elástico. Black Friday é a melhor comparação para você ter em mente, falando de elasticidade. Porque aqui a gente fala muito sobre conjuntos de máquinas no modelo Scale Set, onde nós vamos ter aqueles recursos, por exemplo, eu posso dizer que eu vou começar com duas máquinas, e quando essas máquinas chegarem a 90% de acesso a recurso computacional, eu vou crescer mais duas máquinas. E assim ele vai fazendo uma média entre todos os hosts, enquanto eles estiverem sendo muito utilizados, vai crescendo até chegar em um ponto limite, e quando elas começarem a não serem tão requisitadas assim, essa quantidade de máquinas vem diminuindo. Isso eu posso fazer em um modelo automático ou em um modelo manual. Claro que o modelo manual não é tão bonito, se utilizar um modelo automático, onde você vai colocar uma regra de alteração, é muito melhor. Mas são as formas que a gente pode trabalhar dentro desse contexto. Então falando de elasticidade, lembre-se sempre de Black Friday. E lembre-se do elástico, ou seja, você pode estender e ele pode voltar a como ele estava anteriormente, quando você não estava puxando. Então o conceito de escalabilidade é quando eu vou aumentar o meu recurso computacional para atender uma determinada necessidade, ele vai se manter, e quando eu falo de elasticidade, eu estou adaptando os meus recursos com base em uma necessidade que está ocorrendo naquele momento. E assim que aquela necessidade for diminuindo, os meus recursos também diminuem com ela. Falando de alcance global, nós sabemos que todos os providers oferecem um número muito grande de data centers, de regiões, onde nós podemos criar os nossos recursos. Então se nós estamos falando de uma empresa multinacional, por exemplo, perceba que eu posso ter os meus recursos aqui no Brasil, eu posso criar recursos lá no Japão, posso criar recursos na Europa, nos Estados Unidos, na Oceania, nós temos data centers em todos os continentes. Então esse alcance global automático já existe lá. Esse data center é só eu criar da mesma forma como eu crio aqui. Perceba que o alcance global ajuda demais a expansão de empresas que já trabalhavam no modelo de multinacional. A capacidade de latência é outra coisa interessante, porque ainda que, claro, nós vamos ter uma questão de comunicação, latência entre regiões, principalmente quando nós falamos de continentes diferentes, mas nós estamos trafegando pelo que a gente chama de backbone da Microsoft, quando nós estamos falando de Azure, então nós temos um link direto entre essas regiões e além de termos um alcance global, nós vamos ter uma latência muito menor de comunicações do que se a gente estivesse indo pela internet tradicional. A questão de falar sobre agilidade, a gente pode associar essa questão do self-service, aonde você acessa um portal, já existem os recursos ali, você clica, compra, personaliza e em questão de segundos ou minutos você já pode sair utilizando esses recursos. Então é muito mais ágil, você não precisa ficar fazendo orçamento, não precisa esperar chegar nada de recursos físicos e assim você diminui também a força operacional em cima destes recursos que você está utilizando. A questão sobre os custos, nós estamos falando muito sobre as despesas, capex versus opex, aonde aquela despesa onde eu pago na frente, eu estou falando principalmente do modelo on-premise, eu vou utilizar o capex e a despesa operacional, estamos falando do opex para os recursos que a gente cria na nuvem. Recuperação de desastre não confunda com tolerância a falhas. Lembre-se, a tolerância a falhas é quando ainda que eu tenha alguma perca do meu ambiente, o meu usuário não vai notar que algo está errado. Na recuperação de desastres é quando eu tive um problema, o meu ambiente acabou precisando de um que a gente chama de DR, que seria um desastre recovery em inglês, mas a gente precisa subir o nosso ambiente em outra região. Por exemplo, estamos aqui com um grupo de máquinas na região do Brasil e nós temos uma réplica dessas máquinas trabalhando nos Estados Unidos. A região do Brasil aconteceu uma catástrofe, ela está indisponível, ou seja, cortou o acesso dos meus usuários, eles não estão mais acessando meus clientes, está tudo fora. Mas eu tenho essa réplica lá nos Estados Unidos, eu vou subir essa réplica agora e a partir daí eu consigo subir o meu ambiente novamente. Perceba que nós tivemos um tempo de indisponibilidade, já temos um how-to de como que nós vamos fazer essa virada para fora e a partir daí nós começamos a executar manobras e o nosso ambiente começa a subir em outra localidade. Isso é recuperação de desastres, benefícios da nuvem. Você já tem um ambiente em espera, digamos assim, em uma outra localidade pronto para que em caso de desastre você possa acionar esse ambiente. A questão da segurança, ela entra bastante em debate, porque o que acontece? Falando da segurança, responsabilidade do provider, nós podemos conectar na nuvem pela VPN site to site, VPN point to site, um express route, todo esse ambiente vai ser criptografado, as máquinas vão ter discos criptografados, nós temos uma questão de criptografia na internet quando essas informações estão sendo trafegadas. Porém, nós vamos ver mais adiante que existem itens de segurança que não são responsabilidade do provider e nós, como profissionais de cloud, precisamos entender bastante sobre essa questão de quando a gente vai fazer a criação de um item, quem é responsável pelo quê? Modelo de responsabilidade, provider e cliente. Mas em suma, os itens criados e toda a informação trafegada dentro do modelo de nuvem, ela tem também a segurança, está tudo criptografado, para garantir que ainda que seja capturado algum dado durante o caminho, não vai valer a pena tentar descriptografar, porque ela vai estar em cima de uma criptografia muito alta, não vai valer a pena o esforço. Beleza, pessoal? Então vamos para o próximo aqui, comparando os nossos modelos de capexes e opex, a despesa de capex, como eu havia mencionado, nós estamos falando de um gasto inicial, ou seja, você paga na frente, você precisa adquirir novos servidores, então você vai lá, faz três orçamentos, valida o que cada fornecedor lhe passou, acerta com um deles e paga. Depois disso, você recebe o seu servidor e depois disso, você vai fazer toda a configuração e liberar o ambiente para os seus usuários ou até mesmo para o setor responsável ir ali e fazer as configurações finais. Isso é uma despesa de capital, quando você paga na frente. As despesas operacionais, muito associadas com nuvem, é gastos em cima daquilo que você comprou, em cima do tempo que você utilizou e que você vai pagar 30 dias após você ter feito a compra, adquirir, literalmente quando vir a sua fatura lá no provider. Então, quando a gente vai adquirir um serviço, por exemplo, se você cria hoje uma conta trial, uma conta de 30 dias, você foi lá, criou a conta, começou a utilizar o portal. Eu vou criar uma máquina virtual para ver como é. Você cria aquela máquina e ele vai lhe dizer, isso aqui por 30 dias, assim, assim, vai gastar na média de tanto. Você vai lá, beleza, ok, ele vai criar a máquina. Só que, claro, aquilo ali, ele está fazendo uma conta em cima de todo o tempo daquele mês, aquela máquina ligada. Agora você criou a máquina, olhou assim, ah não, mas eu acho que eu criei uma Windows, eu criei uma Linux, então vou excluir essa máquina e vou criar outra. Você vai lá e exclui a máquina. Você não tem nenhum contrato nesse modelo, ah, você tem que usar a máquina para aquele tempo todo. Você não utilizou um modelo de reserva, você só criou no modelo Pays to Go, que é o pagar conforme o uso. Isso é um modelo de despesa operacional. Então você vai receber a conta depois e vai ter lá os registros de tudo aquilo que você utilizou. A PECs nós estamos pagando na frente, o PECs nós estamos pagando conforme o tempo de uso. Esse modelo baseado em consumo, nós estamos falando sobre os provedores de nuvem, onde nós vamos ter apenas na nossa fatura, digamos assim, aquilo que nós usamos dentro de um X tempo. Ou seja, nós conseguimos avaliar quanto nós vamos gastar, a cobrança pode ser em cima de real hoje, não precisa ser em cima de dólares, a gente consegue trocar a taxação. E claro, nós temos os recursos individualizados, conseguimos gerenciar melhor a questão de custos, garantimos que vamos estar utilizando os itens e pagando somente por aquilo que foi usado. Por exemplo, você criou um recurso, nesse momento, passou 5, 10 minutos, assim que ele foi criado, você se lembrou, nossa, não era isso que eu tinha que ter criado, vai lá e exclui, você vai pagar apenas pelo tempo que ele ficou em atividade. Então aqui a gente garante que nós vamos conseguir redimensionar o valor, por exemplo, valores de máquinas, valores de computação, a partir do momento que você marca uma máquina para ela desligar e ligar automaticamente, o tempo que ela ficou desligada, você vai pagar apenas pelo disco, por exemplo, não vai ter uma questão de pagar pelo recurso computacional 100%, não, vai diminuir bastante o valor. Se você faz uma reserva de máquina, você vai pagar menos, se você trazer uma licença híbrida, você também vai pagar menos, então nós conseguimos dimensionar o valor gasto com os nossos recursos com base no modelo, com base na região, e a gente vai falar sobre esses detalhes um pouco mais adiante aí na nossa aula. E indo para o nosso próximo tópico, falando sobre os serviços de nuvem, os pilares dos nossos serviços, vamos começar primeiro com infraestrutura como serviço, que é o modelo mais fácil, digamos assim, de nós visualizarmos como que está sendo a criação dos nossos itens, infraestrutura como serviço é a grande cereja do bolo, mas conforme as nossas aplicações vão se modernizando, ela também vai entrando em desuso, o que você precisa saber é que um principal representante da infraestrutura como serviço na nuvem são as máquinas virtuais, os sistemas de armazenamento, os nossos sistemas operacionais, então quando você cria um host na nuvem, independente se ele é Linux, se ele é Windows, qual que é a versão, qual que é a potência, a família dessa máquina, ela é uma infraestrutura como serviço, então você remove aquela necessidade de um recurso computacional dentro do seu ambiente on-premise e traz isso para a nuvem, lembrando, vou fazer isso no modelo PSIO Go, vou utilizar reservas, aí vai ser indiferente, vai avaliar o seu modelo, mas infraestrutura como serviço, nosso grande representante aqui serão os serviços de armazenamento em nome de máquinas virtuais, os nossos servidores, então esse é o nosso primeiro pilar, infraestrutura como serviço. Plataforma como serviço, nós abstraímos a parte do host, abstraímos a parte do acesso ao sistema operacional e aqui nós vamos para um outro patamar, vamos utilizar diretamente a plataforma. Perceba que quando nós criamos uma infraestrutura como serviço, ou seja, criei um conjunto ou uma máquina única, eu não tenho acesso ao hardware dessa máquina, eu não sei em qual servidor físico ela está, porém é minha responsabilidade que eu gerencie atualizações, que eu gerencie as aplicações que vão estar ali, que eu crie um backup, isso não vai se criar sozinho, então, apesar de eu não ter acesso à máquina física, ao portal, o modelo individual dela, o acesso ao host, eu vou ter, então tudo eu tenho que configurar. Quando a gente parte para a plataforma como serviço, nós pulamos essa etapa também. O grande representante da plataforma como serviço são os serviços de bancos de dados, onde ainda que quando a gente cria um SQL, por exemplo, na nuvem, nós podemos atribuir a ele um modelo de computação, mas nós não temos acesso ao host, então, eu não tenho acesso no sistema operacional para fazer alterações. Aqui eu já estou configurando diretamente a minha aplicação, eu abstraio essa camada de acesso e aqui eu tenho um poder maior de automatização também das coisas, e a Microsoft também absorve mais itens para ela do que no modelo de infraestrutura como serviço. Quando nós falamos no último item, que é o software como serviço, um grande representante são as ferramentas de e-mail, como o Microsoft 365, onde nós não temos acesso ao sistema operacional, nós não necessariamente configuramos a aplicação, porque ela já é previamente configurada, mas aqui nós apenas fazemos a configuração para o nosso ambiente, ou seja, se eu tenho um acesso para o Office 365, a minha empresa tem 200 pessoas, uma empresa com 2 mil, com 5 mil pessoas, se nós compramos o mesmo modelo de licença, nós vamos ter os mesmos botões, os mesmos acessos, as mesmas permissões, só vamos configurar. Então, perceba que aqui, quando a gente vem subindo o nível na questão de modelo de serviço, diminui a responsabilidade do cliente e aumenta a responsabilidade do provider, nós invertemos essa conta, porque quando eu falo sobre o software como serviço, referenciando o 365, aqui eu vou fazer a gerência das minhas contas, a gerência de como está configurado o endereço da minha empresa, o meu domínio, qual é o modelo de licença que eu tenho, como é que eu vou atribuir as minhas regras, mas a plataforma já está pronta. Eu não sei em que sistema operacional que está, qual a localidade que está, isso não é minha responsabilidade. Então, focando bastante nesse item, nós temos aqui esses três grandes pilares, falando sobre o modelo de responsabilidade, é claro que ainda que a infraestrutura como serviço nos dê mais responsabilidades em relação às demais, ainda assim nós podemos crescer essa infraestrutura, podemos administrar ela de uma forma muito mais eficiente do que trabalhando apenas com máquinas físicas, mas sim, nós temos uma maior responsabilidade de gestão e gerência. Então, você configura a parte do seu sistema operacional, você vai configurar backup, vai configurar timezone, se você vai garantir que ela vai desligar, ligar, tudo é sua responsabilidade, é um serviço mais flexível do que o ambiente on-premise, com certeza, mas você tem uma parcela maior de culpa caso alguma coisa não dê muito certo. Quando nós falamos do modelo de plataforma como serviço, aqui nós estamos focando principalmente em aplicativos, bancos de dados, você não precisa se preocupar com o sistema operacional em si, você quer se preocupar com as informações, como que você vai fazer a gestão dos dados e a gerência desses dados. Então, falando de plataforma como serviço, eu não tenho acesso ao sistema operacional, eu tenho acesso à minha aplicação. E no software como serviço, nós subimos ainda mais, porque a nossa aplicação já está previamente configurada e aqui nós vamos fazer a gestão dos dados. Então, nós vamos garantir aqui um modelo de assinatura e só com base na assinatura que vai diferir quem acessa o quê, porque nós vamos ter aqui features a mais do que outra empresa, mas essa plataforma, perceba, ela já é padronizada. Então, nós temos um menor esforço operacional, falando do modelo de software como serviço. Aqui nós temos uma explicação melhor, digamos assim, com relação à visualização de qual é a sua responsabilidade, você como profissional, e qual é a responsabilidade do seu provider dentro do modelo de responsabilidade compartilhada. Como eu havia falado, nuvem privada, seu data center na sua empresa, tudo é sua responsabilidade. Então, nós partimos da informação que você cuida dos recursos computacionais, você vai cuidar desde o ar-condicionado lá da sala, se está funcionando ou não está, é você que vai ter que saber o que vai fazer, você tem que garantir cabeamento, você tem que garantir atualizações de sistema operacional, instalação de aplicações, tudo é sua responsabilidade. Quando nós partimos para a infraestrutura como serviço, nós pulamos a parte de gestão física, onde nós não sabemos onde estão os computadores, eu não sei o status da minha sala, eu não sei se o cabeamento está ok, isso não é minha responsabilidade. Porém, a partir do momento que eu subi uma máquina no meu ambiente, escolhi o modelo de sistema operacional, ela começou a rodar, acesso, dados, permissionamento, backup, acesso de rede, tudo é sua responsabilidade. Quando nós falamos de plataforma como serviço, perceba que nós abstraímos a parte do host, e dessa forma a gente vai trabalhar com os dados, o acesso, e a configuração daquela aplicação, porque eu posso escolher um modelo de App Service, eu posso escolher um modelo de banco de dados, eu vou dizer qual é a versão, eu vou dizer como é que eu quero aquele modelo, qual vai ser a capacidade computacional que vai estar rodando ali, e depois eu vou administrando as informações que vão estar lá dentro. Quando nós falamos de software como serviço, se sobe ainda mais essa régua, porque eu não tenho acesso aos recursos computacionais, eu nem quero acesso a eles, eu não tenho acesso ao aplicativo em si, eu só quero configurar algo que já está previamente pronto. Eu chego ali no Office 365, eu escolho qual é o meu modelo de licença, adquiro aquela aplicação, e agora eu vou só configurar. Então, eu tenho muito menos gestão, e claro, esforço operacional em cima disso, que é o mundo ideal, mas sabemos que nem tudo pode trabalhar em cima de software como serviço, mas é notório que quanto mais o tempo passa, menos nós vemos a influência de infraestrutura como serviço, porque isso a longo prazo torna a nuvem muito cara, então as empresas aos poucos já estão trabalhando mais com o modelo, principalmente de plataforma como serviço. Falando sobre computação sem servidor, aqui seguindo aquela informação que eu tinha falado no slide anterior, que as empresas hoje já visualizam melhor seus ambientes de nuvem e repensam em ficar acumulando máquinas virtuais, porque como eu mencionei, máquinas virtuais a longo prazo acabam se tornando caras, então nós temos que adotar algumas estratégias para diminuir essa questão de custos, porém a computação sem servidor vem para nos ajudar a garantir um ambiente estável e claro, mais em conta. Até tem dois exemplos aqui que nós vamos falar sobre eles mais adiante nas próximas aulas, que é o Azure Functions e os aplicativos lógicos do Azure. São exemplos de modelo de computação sem servidor, onde nós conseguimos provisionar, escalar e gerenciar nossa infraestrutura. Tanto o Azure Functions, nós podemos associar ele em vários cenários dentro do Azure, automatizando processos, disparando alertas e a parte de aplicativos lógicos na automação também, enorquestração de processos empresariais e fluxos de trabalho dentro de modelos de sistema e de serviços. Então ficam aqui dois modelos para vocês já irem se habituando, falando em conceitos de prova, nossos representantes aqui, que seriam o serverless, o computação sem servidor. E agora vamos para o nosso teste de conhecimento, avaliar sobre todos os itens que nós vimos neste primeiro vídeo. Lembrando, são cinco vídeos onde nós vamos estar abordando todos os tópicos desta prova. Vamos para a nossa primeira questão. A sua empresa planeja migrar todos os seus recursos de rede para o Azure. Você precisa iniciar o processo de planejamento explorando o Azure. O que você deve criar primeiro? Alternativa A, um grupo de recursos. Alternativa B, uma virtual network. Alternativa C, um grupo de gerenciamento. Ou alternativa D, uma assinatura. Pessoal, dentro desse contexto, aqui já tem uma questão muito parecida com o que você pode ter na sua prova, a Z900. Se você precisa virar, independente se vai todos os seus recursos, se vai uma parte, se você quer explorar o Azure, a primeira coisa que você precisa fazer, se você quiser acessar o Azure, vai ser uma assinatura. Aqui não tem muito contexto com grupo de recursos, virtual network ou grupo de gerenciamento. Seu primeiro passo é criar uma assinatura. A partir do momento que você criou uma assinatura, aí sim você tem acesso aos recursos dentro do Azure e começa a criar o seu ambiente, as suas redes e tudo mais. Próxima pergunta, a sua empresa tem uma rede local que contém vários servidores. A empresa planeja reduzir as seguintes responsabilidades administrativas dos administradores de rede. Fazer backup de dados de aplicativos, substituir servidor com falha, o hardware de servidor com falha, gerenciar a segurança do servidor físico, atualizar sistemas operacionais de servidor, gerenciar permissões para documentos compartilhados e a empresa planeja migrar vários servidores para máquinas virtuais do Azure. O que a galera quer saber? Você precisa identificar quais responsabilidades administrativas serão reduzidas após a migração planejada? Quais são as duas responsabilidades que você deve identificar? Aqui nós temos um total de cinco opções, lembrando que temos mais de uma resposta correta. Pois bem, se nós vamos migrar o hardware de servidor com falha, gerenciar a segurança do servidor físico, atualizar sistemas operacionais, são tarefas e responsabilidades administrativas que eu não quero mais ter. Então, vamos às nossas opções. Fazendo backup dos dados do aplicativo, gerenciando a segurança do servidor físico, gerenciando permissões para documentos compartilhados, substituindo o hardware do servidor com falha ou atualizando os sistemas operacionais de servidores. As duas responsabilidades que agora nós não vamos mais ter vai ser gerenciar a segurança do servidor físico, porque, como eu combinei com vocês, a Microsoft não nos manda um postal dizendo onde está o datacenter do Azure. Então, isso não vai ser mais nossa responsabilidade e também não vai ser substituir o hardware do servidor com falha. Essas são as duas opções corretas dentro desse contexto, porque nós estamos diminuindo as responsabilidades administrativas. Se eu estou indo para a nuvem, isso não é mais minha responsabilidade. Próxima pergunta. Você tem mil máquinas virtuais hospedadas nos hosts Hyper-V em um datacenter. Você planeja migrar todas as máquinas virtuais para uma assinatura paga conforme o uso, PAS e o Gol. Você precisa identificar qual modelo de despesas usar para a solução planejada do Azure. Qual modelo de despesa você deve identificar? Interessante aqui porque nós temos quatro opções, mas nós temos dois modelos de despesa, que é o capital e o operacional. Lembrando que se todas as máquinas hospedadas vão ir para a nuvem, isso quer dizer que eu terei uma despesa operacional. Ou seja, eu não vou mais ter a necessidade de gerenciá-las no meu datacenter e fazer alterações nesses hosts. Independente de serem máquinas virtuais, eles estão hospedados em hosts físicos. Então, aqui nós vamos ter uma mudança. A nossa nova despesa é a OPEX, ou seja, operacional. Você planeja migrar vários servidores de uma rede local para o Azure. Você precisa identificar o principal benefício de usar um serviço de nuvem pública para os servidores. O que você deve identificar? Primeira alternativa, a nuvem pública é uma entidade compartilhada em que várias corporações usam uma parte dos recursos na nuvem. Alternativa B, todos os recursos de nuvem pública podem ser acessados livremente por todos os membros do público. C, a nuvem pública é uma solução de crowdsourcing que oferece às empresas uma capacidade de aprimorar a nuvem. E a última alternativa, a nuvem pública é de propriedade do público, não de uma empresa privada. Então, aqui nós temos essa questão de identificar o principal benefício de usar um serviço de nuvem pública. A resposta correta aqui, pessoal, é a nossa primeira. A nuvem pública é uma entidade compartilhada em que várias corporações usam uma parte dos recursos. Lembra que no início da aula eu comentei que nós não temos um data center para as empresas que pagam mais, um data center para as licenças free de 30 dias. Não, todos utilizamos os recursos da nuvem da mesma forma. Então, aqui falando sobre os serviços de nuvem, nós temos de uma forma geral, uma nuvem pública, ela vai ser uma entidade compartilhada. E aqui nós vamos ter a máquina ali que você criou em cima de uma conta de 30 dias, ela pode estar no mesmo servidor de uma grande empresa. E por aí vai. Sua empresa hospeda uma contabilidade chamada AP1, que é utilizada por todos os clientes da empresa. AP1 tem um baixo consumo durante as primeiras três semanas de cada mês e um uso muito alto durante a última semana de cada mês. Qual o benefício dos serviços de nuvem do Azure da suporte ao gerenciamento de custos para esse padrão de uso? Aqui nós temos um modelo elástico, pessoal, onde aqui ele está comentando que as primeiras três semanas tem muito alto e a última semana de cada mês. Ou seja, eu vou ter uma alteração do acesso e a necessidade desse acesso com base em um período de tempo pré-determinado. Desta forma, o conceito que se encaixa aqui é de elasticidade. Isso que a Microsoft quer saber, se você sabe diferenciá-lo dos demais e que ele é o conceito aqui que está sendo exemplificado. Quais são as duas características das nuvens públicas? Cada resposta apresenta uma solução completa. Uma coisa interessante, pessoal, é que se você faz a prova e tem duas questões que são as corretas e você acerta apenas uma, lembre-se, você vai tirar literalmente um meio certo. Você não vai ter a sua questão anulada. Há um tempo atrás, bastante tempo, a questão era toda invalidada se havia uma resposta errada. Atualmente, não. Se tem três respostas certas e você acerta só uma, você vai receber o valor, a pontuação referente àquela ali que você acertou. Nesse caso, vamos lá, alternativa A, self-service management, conexões não seguras, hardware dedicado, preços medidos ou armazenamento limitado. Características da nuvem pública, self-service management, ou seja, eu vou ter serviços, eu vou ter ali no portal tudo disponível, eu chego, eu escolho o que eu quero, é como se você fosse num mercado. Então você vai ter acesso a todos aqueles recursos, serviços e vai pagar depois conforme o seu uso. E o índice segundo é o preços medidos, pessoal, onde nós vamos ter o valor de cobrança somente em cima do time, o tempo que você estava utilizando aquele recurso e a partir do momento que ele não é mais utilizado, você deixa de pagar. Quando uma máquina virtual do Azure é interrompida, você continua a pagar o custo de armazenamento associado à máquina virtual. Sim ou não? Essa é uma pergunta muito interessante, porque quando a gente exclui uma máquina, todo recurso vai embora. Mas se você estopa essa máquina, ou seja, para ela, diz que ela vai desligar às 7 da noite e liga às 7 da manhã, você deixa de pagar por algumas coisas, mas o custo do seu disco vai continuar em cobrança, você não vai ter acesso porque a máquina está desligada, mas perceba que a Microsoft não pode liberar aquele recurso para outros clientes. Então, sim, mesmo com a máquina desligada, ainda tem uma cobrança por trás. Ao implementar uma solução de software como serviço, ou seja, a SaaS, você é responsável por configurar a alta disponibilidade. O que você faz para implementar a alta disponibilidade? Aqui ele pergunta, instalando a solução, configurando sem alta disponibilidade em SaaS ou definindo regras de escalabilidade? Lembrando que escalabilidade não está referenciando a alta disponibilidade, então essa última a gente já vai excluir ela de antemão. Qual seria a resposta certa, pessoal? Nós estamos configurando a solução SaaS, porque instalar a solução SaaS não tem necessidade, nós vamos estar gerenciando sem alta disponibilidade, também não faz sentido porque, sim, tem alta disponibilidade. Então, aqui o que nós vamos fazer é configurar essa solução. Você tem uma rede local que contém vários servidores, você planeja migrar todos os servidores para o Azure, você precisa recomendar uma solução para garantir que alguns dos servidores estejam disponíveis se um único data center do Azure ficar offline por um período prolongado. O que você deveria incluir nesta recomendação? Então, aqui nós temos uma situação semelhante que eu trouxe durante a aula, onde nós precisamos garantir que esses recursos vão estar disponíveis se um único data center falhar. Qual dessas vantagens está referenciando essa situação? Escalabilidade, tolerância a falhas, elasticidade ou baixa latência? Bom, aqui nós estamos falando de tolerância a falhas, ou seja, eu tenho ciência de que eu vou ter um problema com o meu data center, com aquela máquina onde estava hospedado, mas ainda assim eu terei os meus usuários, meus clientes, acessando o ambiente sem nenhum problema. Então, aqui, tolerância a falhas. Uma organização que hospeda sua infraestrutura em uma nuvem privada pode desativar seu data center. Que tipo de nuvem é recomendado para esta solução? Em um host Hyper-V, uma nuvem híbrida, na nuvem pública ou uma nuvem privada? Bom, se nós vamos desativar o data center, então nós vamos para a nuvem pública. Não pode ter um encaixe aqui de nuvem híbrida, porque não vai mais existir. Em um host Hyper-V, muito menos. E na nuvem privada, não, porque é ela mesmo que está indo para aquele lugar, então aqui não tem mais o que fazer. Sobrou nuvem pública. Então, pessoal, chegamos ao final da nossa primeira aula. Eu espero que você tenha gostado. Deixe os seus comentários aqui neste vídeo. Logo mais, nós teremos o nosso segundo episódio, onde nós vamos estar abordando a continuidade do nosso curso. Se inscreva no canal, nos siga no canal do Telegram, também no Instagram, e agora estamos no LinkedIn. Então, sigam lá, canal da Claudia, e até a nossa próxima aula. Até lá!\n",
            "\n",
            "Transcrição para o arquivo './sample_data/AZ-900 EP 2-5 AZ900 Treinamento Oficial Microsoft Azure Fundamentals.mp3':\n",
            " Música Olá pessoal, tudo bem com vocês? Hoje nós estamos no segundo episódio de uma série de 5 vídeos trazendo treinamento oficial Microsoft da certificação AZ900. Estou abordando todo o conteúdo desse teste em busca de levar você a alcançar o seu pés nessa certificação. Então, bora pro conteúdo de hoje! E neste segundo episódio nós vamos abordar os principais serviços do Azure, falando dentro da cloud, com os componentes de arquitetura e também com os principais recursos. Neste primeiro módulo vamos abordar os componentes da arquitetura do Azure e falando inicialmente das regiões. Pessoal, quando nós falamos do conceito de cloud computing como um todo, desde Azure e AWS ou outros providers, pense que nós temos sempre regiões soberanas, onde nós vamos ter os data centers do provider e ali nós vamos fazer a criação dos nossos recursos. Atualmente nós temos mais de 60 regiões representando mais de 140 países, falando de Microsoft Azure. No Brasil nós temos a região South, estamos com uma outra região já crescente, em questão de absorção de conteúdo, de requisitos e também onde nós podemos criar os nossos recursos, mas ela ainda não está configurada como uma região 100% par. Até eu vou trazer aqui alguns links onde a gente vai olhar essas configurações e eu vou mostrar pra vocês como está funcionando hoje ao vivo, como está o ambiente do Azure e quais são as regiões onde você pode tirar até mesmo algumas dúvidas. Se você está fazendo um projeto, precisa fazer uma avaliação para um cliente e ali você consegue mostrar em tempo real como é que está a estrutura, falando de Microsoft Azure. O que é importante você evidenciar e ter bem em mente, porque também é um requisito que cai na prova, é que uma região é composta de um ou mais data centers, a gente sempre diz que nós estamos falando de três data centers, que eles tenham uma baixa latência, a comunicação vai passar pelo backbone da Microsoft entre eles e dessa forma nós conseguimos escalonar os nossos recursos dentro de uma mesma região, fazendo a replicação dos nossos dados. É claro que isso é uma coisa que não é previamente configurada, nós que temos que configurar e eu vou trazer alguns modelos dessa configuração para vocês, evidenciando também no portal. Falando sobre a estrutura do Azure e atualmente, principalmente referente ao Brasil, o que acontece? Nós temos a Lei Geral de Proteção de Dados que contempla algumas informações que não podem sair do território nacional. Então é importante se você estiver fazendo um projeto para algum cliente, você avalie essas informações e se elas podem ser criadas, o feito upload delas em uma outra região que não seja Brasil South e também avaliar a questão de custos, onde nós também vamos olhar como funciona essa questão de avaliar os custos, a calculadora de TCO da Microsoft que a gente chama, onde nós vamos avaliar quanto está custando cada recurso na nuvem. Então falando sobre o termo região, vamos avaliar aqui, temos um site bem bacana onde a gente pode validar onde nós temos pontos de acesso, regiões e como funciona a comunicação da Microsoft através do mundo. Este site pessoal é muito bacana, ele mostra todo o mapa de infraestrutura da Microsoft, eu vou estar deixando nos links aqui do nosso vídeo para que você avalie também. Nós temos um filtro onde a gente pode tanto deixar na legenda a questão de geografias, aqui até ele tem uma validação com relação a como está o tempo, nós podemos filtrar aqui para o modelo de zonas, se ela está disponível ou não disponível, regiões que são compliance, modelos de desastre recovery, onde essas regiões estão disponíveis hoje e pelo site a gente avalia toda a comunicação da Microsoft. Uma coisa bem legal, vamos avaliar aqui o nosso território do saudoso Brasil, nós vemos que nós temos uma região aqui como região do Brasil e olha só que interessante, ao clicar aqui ele já traz para nós, dizendo onde fica, que é uma residência de dados e também dizendo que ele está replicando para os Estados Unidos, ou seja, atualmente nós estamos em março de 2022, a nossa região do Brasil ainda não consegue replicar dentro do território nacional em uma questão de desastre recovery, ainda vai para os Estados Unidos, claro que talvez quando você assistir esse vídeo essa situação já tenha sido alterada, mas nós estamos fazendo ele em março de 2022. Então ao clicar aqui a gente vê para onde que está indo, todos esses risquinhos aqui está falando sobre a fibra da própria Microsoft, a gente vê que nos Estados Unidos nós temos muito mais regiões e aqui a gente consegue avaliar clicando na região aonde que ela fica e como é que fica a questão de replicação, se ela é uma região soberana, nós temos pontos de acesso, aqui está avaliando até a questão de tempo, bem legal aqui falando sobre os ventos e tudo mais e as edges locations também. Então aqui a gente consegue avaliar aonde existe uma presença da Microsoft ao redor do globo, esses pontos menores são os data centers, aqui já aparece o data center do Rio de Janeiro, mas ele ainda não aparece como sendo uma segunda região, apenas como um location. Então esse site é muito legal, a gente consegue avaliar toda a infraestrutura da Microsoft em termos de Edge, para onde a gente está fazendo as replicações, onde nós temos pontos de acesso e o que cada um desses itens aqui está nos referenciando. Isso aqui é muito legal até mesmo se você vai fazer uma apresentação para um cliente, quer justificar alguma coisa, trazer porque por ser o visual, às vezes fica um pouco mais bacana de exemplificar. Então vamos voltar para a nossa apresentação. E voltando aqui para o conteúdo pessoal, vamos para os pares de regiões. Como eu estava mostrando para vocês ali na parte do mapa, nós temos hoje a região do sul do Brasil sendo replicada para os Estados Unidos ainda. Então perceba que cada região independente, Brasil acaba fazendo a replicação para fora do território nacional, mas todas as regiões vão ter uma região par. Então ali independente se é dentro ou fora do mesmo território nacional, mas a gente vai ter essa opção. Por quê? Isso vai ser muito associado quando a gente for criar um ambiente de desastre e recovery, onde a gente precisa evidenciar para onde vai os itens, onde eu vou ter um ambiente que possa literalmente ser a réplica do meu ambiente atual pensando em uma situação de crise. Então nós temos essa prática de pares de regiões para garantir um plano de continuidade de negócio. O que você precisa saber em termos de prova, principalmente, é que a réplica dos seus serviços dentro da sua região garante que eles vão continuar ativos se um data center ou dois ficarem disponíveis. Se você está replicando em toda a sua região. Porém, para garantir que o seu serviço continue em atividade mesmo que uma região, ou seja, a região onde ele está alocado no momento, fique indisponível, você precisa configurar um modelo de replicação para uma região secundária. Por isso nós temos os pares de regiões. E, dando continuidade no assunto, vamos falar sobre as opções de disponibilidade. Pessoal, tomem nota, prestem bastante atenção e revisem este modelo antes de irem para a prova. A Microsoft gosta de perguntar sobre SLA. Então SLA é aquele nosso termo de disponibilidade de serviço, onde o provider vai garantir que um serviço vai ficar disponível por X tempo, que a gente tem 99,9% para uma UVM e 99,99% para zonas de disponibilidade. Não temos SLA para recuperação de desastre ou disaster recovery. O que a Microsoft gosta de perguntar? Você tem uma single VM ou VM única, se você estiver fazendo a sua prova em português, e você precisa reportar qual é o SLA dela nesse contexto. E você tem que se lembrar. Mas vou ter que me lembrar do número? Sim, você vai ter que se lembrar do número. A Microsoft gosta de perguntar. Por isso eu digo, tome atenção, tome nota e garanta que você se recorda destes números, porque cai bastante em prova relacionada ao tempo de SLA. Ou de uma VM única, ou nesse exemplo do meio, onde nós temos zonas de disponibilidade, onde SLA vai para 99,99%. Mas qual é a lógica? Valeria, eu não estou entendendo. Tem esses números, eu tenho uma VM sim, eu tenho disaster recovery e não tenho. Eu não estou entendendo a lógica dessa questão. Pois bem, você vai criar um host, modelo infraestrutura como serviço, lá no portal do Azure. Ele é uma única máquina sozinha. Você selecionou que quer criar ela na região do Brasil, por exemplo. Perceba que a região do Brasil vai ter o quê? Três data centers. Ou seja, a sua máquina não vai estar nos três, ela vai estar em um deles. Se esse data center cair, você perde acesso à sua máquina, porque ela estava ali. Por isso que um SLA de uma VM, que ela está configurada em zonas de disponibilidade, vai ser maior. Ou seja, a Microsoft lhe garante uma disponibilidade maior, porque ela trabalha semelhante a um modelo de replicação. Ou seja, eu vou ter esse conjunto de disponibilidade, digamos assim, dentre os três data centers em uma região. Eu vou precisar perder os três para ficar sem acesso ao meu serviço. Sendo que, se eu tenho uma VM única, perdendo um data center, sendo que geralmente a gente leva em consideração que aquele que cai é onde está a nossa máquina, por exemplo, Lady Murphy, pode dar errado, dar errado. Então a gente configura que ela vai ter 99,9 de disponibilidade. A questão de recuperação de desastre e recovre, como é que ela funciona, pessoal, para você entender. Se você tem um ambiente, por exemplo, na região do Brasil, e você quer configurar um desastre e recovre, perceba que você não vai ter os dois lados ativos. Ele não é um ativo passivo. Ele é um ativo de um lado e um desligado do outro. Então a primeira região tem que ficar fora, onde ele estava em atividade, e aí você vai subir os seus serviços na região que seria a região par, onde ele estava lá. Por isso que desastre e recovre não tem SLA. Na documentação da Microsoft diz que nós temos pelo menos duas horas aqui para conseguir colocar o serviço no ar, mas isso vai demorar muito e depender de o que nós estamos configurando, qual é o serviço que nós estamos subindo. Então não temos um SLA declarado aqui em porcentagem como os outros dois modelos. Então quando nós temos um par de região, não é automático, pessoal. Isso você precisa saber, porque às vezes confunde, ah, recuperação de desastre, então eu tenho aqui os computadores de um lado, se aqui ficar tudo fora, eu ligo lá no outro e está tudo certo. É, vai funcionar, mas não é tão automático assim. Isso até é importante quando a gente está fazendo uma venda para um cliente, explicando alguma coisa para as pessoas não acharem que, ah, então essa região aqui ficou fora, dois minutos depois a outra lá está sumindo. Então é bem por aí, tem uma demora entre um lado e o outro, existem registros que a gente precisa ajustar, muitas coisas que tem que deixar já previamente configurada para garantir que vai funcionar tudo certinho. Então perceba que nós temos um SLA diferenciado para cada modelo de serviço que a gente vai colocar no ar. Sobre zonas de disponibilidade, isso é muito interessante, cai bastante em prova e essa é uma configuração muito bacana que a gente faz para garantir um modelo de plano de continuidade de negócios também. O que seria uma zona de disponibilidade? Aqui até nesse desenho nós temos os nossos domínios e aqui nós temos a zona 1, zona 2 e a 3, simbolizam os três data centers da Microsoft dentro de uma região. Quando a gente configura desse modelo, nós estamos literalmente alocando as nossas máquinas em hacks diferentes e em máquinas diferentes. Perceba que quando você cria uma máquina lá no Azure, você está criando uma máquina virtual, ela está numa hospedeira. Semelhante você que já trabalha com VMware, Hyper-V, seria a mesma lógica, ela está dentro de uma hospedeira, mas a gente não sabe que hospedeira é essa e em termos de hardware a gente não sabe qual é o número do hack que ela está, a gente não sabe qual que é a máquina física, onde ela está configurada. Então quando nós criamos dentro de zonas de disponibilidade, eu estou garantindo que as minhas máquinas não estão no mesmo hack, elas não estão dentro do mesmo host, ou seja, assim eu consigo separar ela fisicamente dentro de um data center e também consigo replicar isso dentro da região. Porque perceba que quando a gente fala da máquina virtual, ela precisa de uma hospedeira e nós precisamos garantir que se a gente tiver um domínio de falha ou se a gente tiver um domínio de atualização, nós não seremos afetados a ponto de o nosso serviço ficar indisponível. Quando que isso pode acontecer? Se todo um hack, ele ficar sem alimentação de energia, todas as máquinas que estão ali vão ficar indisponíveis. Se a máquina física, onde a minha VM estiver conectada, for passar por um processo de atualização, se ela precisar de um reboot, se ela precisar de uma troca de peça, uma manutenção de hardware, todas as máquinas que estão ali, elas vão ter que serem alocadas para outro host físico e esse processo pode gerar indisponibilidade. Agora perceba que se você cria três máquinas, elas estão dentro do mesmo data center, elas podem estar no mesmo hack. Se aquele hack cair, todo o seu sistema cai. Se eu configurar em zonas de disponibilidade, eu estou garantindo que essas máquinas não vão ficar fisicamente no mesmo local. Então isso nos dá uma melhor visão sobre como que está a nossa estrutura e garante uma maior disponibilidade na prática. Vamos falar um pouco sobre os recursos do Azure. Agora que nós já avaliamos o modelo de recursos, onde a gente tem os principais, infraestrutura como serviço, como as máquinas virtuais, plataforma como serviço, que seriam os bancos de dados e também o software como serviço, principalmente o Office 365, esses são apenas alguns elementos que nós encontramos falando de recursos. Nós temos vários itens, não apenas Microsoft, mas também nós temos o Marketplace lá dentro do portal. Vamos dar uma olhadinha? Quando nós acessamos o portal do Azure, nós temos esse menu aqui à esquerda, lembrando pessoal que nós podemos configurar aqui no botão de configurações, deixar tanto com a telinha branca, telinha preta, trocar o idioma. Aqui no momento meu está em português, mas eu poderia trocar para inglês ou outro idioma. Aqui nós podemos pesquisar os recursos. Aqui esse botãozinho dos Cloud Shell, onde ele vai inicializar um modelo de storage account. Nós podemos criar itens através de comandos, seja ele o comando Bash ou também o PowerShell. Ele sempre vai pedir para criar um armazenamento, um storage account caso não tenha. Mas depois a gente vai dar mais uma olhadinha. Eu já vi em questões de prova o pessoal comentando que cai um print desse botão e pergunta quem é esse cara. Então lembre-se, ele é o Cloud Shell. Então aqui quando a gente vem no portal da Microsoft, a gente pode vir aqui em todos os serviços. Nós temos o nosso Marketplace, onde nós viemos aqui por categorias, podemos associar serviços, criar recursos. Temos aqui vários modelos, independente daquilo que você está precisando criar, a Microsoft oferece uma série de opções. Então quando nós estamos aqui no portal, você pode pesquisar. Assim que você começa a escrever, ele já traz os modelos de recursos que a gente vai poder criar. No portal da Microsoft, a gente não tem só itens Microsoft. Por exemplo, você pode criar no seu ambiente e dizer, eu não gostaria de utilizar o Fyro do Azure, mas eu gostaria de utilizar um Cisco, por exemplo. Aí você vem aqui no Marketplace e pode ver que tem vários modelos, não apenas de Cisco, mas existem outros também. Então aqui no Marketplace seria a nossa lojinha da Azure, onde você pode ver todos os itens que existem disponíveis. É importante você avaliar, quando você está criando um recurso, olhando para um recurso, se aquele recurso porventura não está em preview. O recurso está em preview, ele ainda está sendo testado e neste momento de teste ele não possui um SLA. Inclusive se a Microsoft quiser, ela pode revogar aquele recurso e não disponibilizá-lo para produção. Então é muito importante ter atenção quando vai criar alguma coisa para garantir que ela não está em preview. Então aqui, por exemplo, a gente pode vir para criar uma máquina virtual, que foi um dos modelos que a gente estava comentando no outro slide. Uma coisa super importante, pessoal, quaisquer recursos que você for criar no Azure, ele não pode ser criado sem que haja um grupo de recursos. Tem que você criar na hora que você está criando aquele item, mas nenhum recurso é criado no Azure sem um grupo de recursos. Por quê? O grupo de recursos não está associado necessariamente a uma região. Eu posso ter um grupo de recursos que estão no Brasil e tem outros itens que estão nos Estados Unidos, tem itens que estão na Europa. Ele serve mais para uma organização. Mas nenhum item, nada, nada, nada é criado no Azure sem que esteja associado a um grupo de recursos. Então aqui pode ver que ele já selecionou para mim até a mesma máquina Ubuntu. Nós temos Oracle, SUSE, Red Hat, CentOS, temos várias versões de Microsoft, Windows Server. Então nós temos aqui uma coisa interessante até para mostrar. Olha só, pessoal, quando eu trago para a Microsoft, se eu tiver uma licença e eu for utilizar o benefício híbrido, ou seja, eu vou utilizar a licença que eu já tinha lá na nuvem, eu consigo um desconto de até 49%. Então se eu for utilizar uma licença existente. Isso é um item muito interessante, é uma daquelas coisas que eu havia comentado, que vai alterar o preço de uma máquina. Ou seja, só porque nós temos duas máquinas iguais, uma do lado da outra, não quer dizer que estamos pagando mesmo por essas máquinas. Por exemplo, se nós vemos aqui em banco de dados do SQL, por exemplo, aqui nós vamos estar utilizando o modelo de plataforma como serviço. Perceba que eu vou ter aqui uma questão de computação e armazenamento, onde eu vou escolher os recursos, mas eu não tenho acesso ao sistema operacional. Então eu estou usando o modelo de PAS, hashtag PAS, plataforma como serviço. Aqui eu vou dar o nome, vou selecionar, vou criar um servidor, vou dizer como que vai ser o modelo desse servidor, o modelo de backup, se ele vai ter uma redundância local, de zona ou geográfica, e depois disso a Microsoft vai gerenciar esses backups por mim. Se eu fizesse a criação de uma máquina virtual, lembrando o backup eu que teria que criar, a Microsoft não vai fazer o backup dessa máquina para mim. E por exemplo, se a gente for criar aqui, por exemplo, uma conta de armazenamento ou storage account, o storage account também é um item bem interessante, onde nós podemos utilizar o armazenamento de blob, nós podemos criar files, podemos criar tables ou filas, para que serve esse cara? Muitas coisas, desde armazenamento de banco de dados, imagem de máquina, aquela pastinha compartilhada que você utilizava na rede, esse cara aqui vai lhe ajudar dentro desse processo. E uma coisa importante que eu queria mostrar para vocês antes de nós avançarmos, a parte de replicação. Esses itens de replicação nós vamos precisar analisar individualmente, nos próximos slides a gente vai ver esse modelo, mas o modelo de replicação vai implicar em o quanto o meu sistema vai ficar ativo em caso de falhas. Então vamos voltar para o slide. Vindo aqui ao nosso slide, nós temos outros modelos aqui, como também redes virtuais, funções, serviços de aplicativos, mas como você viu lá pelo portal e no marketplace, nós temos muito mais itens dentro do portal da Microsoft. Na verdade ele suporta que você crie uma estrutura totalmente na nuvem, assim como você teria uma estrutura dentro do seu ambiente físico. E deveras às vezes até de uma forma muito melhor, sem contar que muito mais otimizada e com SLA muito melhor do que se a gente tivesse que ficar configurando máquina para cima e para baixo. Então vamos dando continuidade aqui. Os nossos grupos de recursos. Lembra que eu comentei pessoal, nenhum item é criado sem que haja um grupo de recursos. Então vamos fazer a nossa primeira analogia. Para que você comece a utilizar os serviços do Azure, você precisa de uma assinatura. A partir do momento que você tem uma assinatura, você começa a utilizar os serviços. Cada item que você cria dentro do Azure precisa de um grupo de recursos e o grupo de recursos não amarra os seus recursos a uma região. O seu grupo de recursos pode estar lotado, digamos assim, registrado para o Brasil, mas ele tem recursos que são dos Estados Unidos, recursos que estão na Europa, que estão no Japão, que estão na África, indiferente. O fato de o grupo de recursos estar em uma região X não quer dizer que as coisas que estão ali dentro precisam estar nesta região também. Uma coisa interessante é que não pode haver um grupo de recursos dentro de outro grupo de recursos. Isso é bem importante de ser citado. E, claro, um recurso não pode estar em mais de um grupo de recursos ao mesmo tempo. E para o nosso próximo conteúdo temos o Azure Resource Manager. Quem é esse cara? A gente tem aqui referenciando o Azure Resource Manager como o modelo em arme, que na verdade fornece uma camada de gerenciamento pessoal. O que acontece? Nós temos aqui citado o PowerShell, nós temos aqui citado o portal do Azure, nós temos o CLI do Azure, Clientes, REST e todos eles, por meio de uma autenticação, requerem que alguém crie os recursos. Ou seja, você está ali no portal, você clica em nova máquina, coloca todas as informações pertinentes e solicita que ela seja criada. Por trás das cortinas, quem está lá validando se aquele item pode ser criado, se você tem autorização para fazer isso, fez autenticação, o Azure Resource Manager. Então ele vai falar uma linguagem que o Azure entende para que sejam criados os itens que você está pedindo. Ele faz isso não apenas através do portal, mas ele é o cara que vai fazer o encaminhamento através de todas as ferramentas que nós temos para criar os recursos dentro do Azure. Não é um item, por exemplo, que você vai administrar, ele é quem faz a criação dos recursos. Então, através do portal ou até mesmo do PowerShell, do CLI, quem está sendo requisitado para fazer a criação, quem está trabalhando por nós é o Azure Resource Manager. A questão das assinaturas do Azure, pessoal, isso aqui é muito importante, é importante que você entenda, preste atenção, porque a assinatura é uma coisa que cai bastante em prova, a Microsoft gosta de perguntar, porque em um primeiro momento ela acaba, de certa forma, confundindo um pouco a cabeça da gente. Quando nós criamos a nossa conta no Azure, automaticamente nós podemos começar a criar os recursos na nossa assinatura. Perceba que nós temos esse ícone da chave que referencia a nossa assinatura. Porém, é muito comum, nós temos por prática dentro das empresas, ter várias assinaturas, porque dessa forma nós conseguimos gerenciar melhor os acessos, conseguimos gerenciar melhor a parte de cobrança, porque cada assinatura pode estar referenciando a um setor, pode estar relacionada a uma região da empresa, uma localidade, então ali vai ter o seu próprio billing, a questão da cobrança. E a gente pode gerenciar algumas coisas a nível de cobrança que são bem interessantes. E uma dessas coisas é por meio de assinaturas, é assinaturas e tags, que a gente vai ver mais adiante quem é também. Então falando de assinatura, nós podemos ter esse nível de cobrança melhor mapeado e controle de acesso dos meus colaboradores. Porém, nós podemos ter várias assinaturas que remetem à mesma conta do Azure, ou seja, eu tenho uma conta e várias assinaturas abaixo. Isso é uma coisa que a Microsoft gosta de perguntar, se uma assinatura vai estar referenciando para uma conta ou se uma conta pode ter várias assinaturas. E aqui pelo desenho a gente já percebe que aquela assinatura ali, nós temos duas, quatro, seis, oito assinaturas e nós temos uma única conta. Às vezes nós temos clientes ali que tem muito mais de oito assinaturas, dependendo do tamanho da empresa. Mas ela remete a uma conta principal e abaixo dessa conta nós temos assim meio que desmembrado, digamos assim, várias assinaturas. Então a moral da história de ter várias assinaturas é para garantir a questão de cobrança e também os acessos. Eu posso ter uma única conta com várias assinaturas. Outra forma de garantir um melhor billing quando o assunto é a cobrança é adicionar tags também a todos os recursos e a gente vai falar sobre essa questão de tag mais adiante. E os grupos de gerenciamento pessoal também são bem importantes. Quem são os grupos de gerenciamento? Bom, nós temos essa questão da assinatura, onde nós podemos ter várias assinaturas remetendo a uma única conta. Eu comentei que a vantagem é a gente conseguir particionar a questão do billing, os custos por cada uma dessas assinaturas e nós podemos também garantir uma melhor administração das permissões e aí que entram os grupos de gerenciamento. Ou seja, cada uma daquelas chaves ali onde eu estou remetendo, eu posso ter um grupo de gerenciamento que vai garantir as permissões. Então esses grupos de gerenciamento, eles podem incluir várias assinaturas também e elas vão herdar essas condições aplicadas. Uma coisa interessante é que ele fornece suporte até 10 mil grupos de gerenciamento em um único diretório, mas eu acho que não chegou nenhuma empresa num nível tão alto assim e provavelmente não seria uma coisa que o Microsoft lhe perguntaria, mas está aqui para informação. Em uma árvore de grupos de gerenciamento, sim, ela pode oferecer suporte até seis níveis de profundidade. Quem são esses níveis de profundidade? Como está o desenho, cada escala, cada nível que ela está trazendo ali, que vai somando mais um e mais um, é até onde ela consegue nos dar suporte, mas esse número também em termos de gerenciamento é bastante alto e é difícil de conseguir passar, digamos assim. Então esse gerenciamento vai estar associado a esse permissionamento que a gente vai trazer para as nossas assinaturas. E vamos para o módulo dois, principais recursos do Azure. Falando sobre os serviços de computação do Azure, nós temos aqui alguns exemplos como as próprias máquinas virtuais, que nós estávamos vendo no capítulo anterior, a parte de serviços de aplicativo, que são os App Services, as instâncias de container e também os serviços de Kubernetes do Azure e o famoso AKS. Não vamos esquecer da área de trabalho virtual do Azure, pessoal. Vamos analisar cada um desses produtos. Primeiramente sobre as máquinas virtuais, nós já vimos que nós podemos incluir tanto máquinas Linux como máquinas Windows. Nós vamos selecionar o modelo de famílias. Lembrando que tem as famílias de determinadas máquinas que incluem recursos computacionais direcionados tanto para memória, processamento, banco de dados, entre outros. Então você pode escolher qual é o modelo mais indicado para o seu dia a dia, para o cliente que você está fazendo um projeto e tudo mais. Isso vai incluir todos os itens de uma máquina comum. Nós temos processador, temos memória, temos armazenamento de rede, podemos escolher qual é o modelo de disco e lembrando que nós estamos falando sobre infraestrutura como serviço. Vamos dar mais uma olhadinha na criação de máquinas lá dentro do Azure? Vamos voltar para o portal. Quando nós vamos criar uma máquina virtual, você pode vir tanto pelo menu suspenso na pesquisa ou aqui na esquerda em máquinas virtuais. Você clica em criar máquina virtual. Ele vai levar para uma outra tela onde você vai primeiramente escolher qual é a assinatura que você está utilizando caso você tenha mais de uma. Quem vem depois? O nosso grupo de recursos. Vou escolher esse grupo laboratório que já está pronto. Você precisa por exemplo dar um nome para a máquina virtual. Vou colocar aqui máquina 01. Após isso, a região. Lembrando pessoal que a região é um dos itens que vai determinar o nosso custo. Depois vamos dar uma olhadinha na calculadora da Microsoft. Vou deixar o link para vocês também para que você consiga avaliar e também ter uma ideia de quanto custa cada dispositivo, cada host. Tudo aquilo que a gente cria na nuvem tem um valor e a gente consegue avaliar pela calculadora ter uma projeção de quanto isso vai nos custar. Eu vou deixar nessa região que ele está sugerindo aqui a parte de opção de disponibilidade. Olha só que interessante pessoal. Nós podemos separar fisicamente através da nossa zona de disponibilidade. Podemos configurar um conjunto de dimensionamento de máquinas ou até mesmo um conjunto de disponibilidade entre vários domínios de falha. Como eu quero gastar menos, eu vou deixar ela assim, sem nenhum modelo de redundância. O tipo de segurança padrão, vou deixar a imagem 2019. Perceba que aqui se a gente vier em todos os tamanhos, ele já vai trazer aqui quais são os modelos de máquinas, famílias e as séries. Aqui nas séries a gente vê, por exemplo, esse modelo de família recomendado para necessidade de uso geral. Aqui nós temos quando não precisam de desempenho total de CPU continuamente, família mais adequada cargas de trabalho ou se não, até mesmo VMs de computação de alto desempenho. Claro que dependendo da família que a gente escolhe, isso também implica no custo. Então a região vai implicar no custo, qual que é a família da máquina também vai implicar no custo. E lembrando que se nós tivermos um modelo de licenciamento onde nós vamos aproveitar uma licença existente, nós também vamos ter uma diminuição de custos. Eu vou colocar aqui um usuário e senha, só para a gente poder avançar. E vamos analisar ali as outras opções. Principalmente a parte de discos. Esse item aqui, excluir com VM é um item relativamente novo, pessoal. Ele não estava aparecendo antes. Para que serve? Antigamente quando nós criávamos uma máquina, quando a gente ia excluir ela, nós tínhamos que excluir todos os recursos associados. Era muito comum. A gente quando ia fazer um projeto, acessava a primeira vez a máquina de um cliente, o ambiente do cliente, a gente achava que a gente chamava de discos órfãos, que eram máquinas que haviam sido excluídas e ficou perdido lá o disco da VM e ninguém estava usando. E isso gera um custo dentro da subscrição. Agora não mais, porque todas as máquinas que estão sendo criadas, elas já vêm por padrão marcada essa opção. Então quando a gente vai excluir a máquina, ele já lista todos os itens associados e questiona se a gente quer excluir os itens junto com a máquina. Outro item que vai trazer aqui uma diferença de custo é o modelo de disco do sistema operacional, ou seja, do SSD Premium até o HDD Standard. Lembrando, o HDD Standard é aquele que vai se tornar a máquina um pouco mais lenta, não é indicado para ambientes críticos, mas para o que a gente está fazendo, um laboratório, não tem problema nenhum. O SSD Standard seria uma opção um pouco mais razoável para aplicativos empresariais e o Premium, como o próprio nome diz, a gente já percebe que ele vai ter o melhor desempenho. Sempre tipo de criptografia, nós podemos utilizar também criptografia em repouso, podemos usar uma chave da empresa, mas já existe uma criptografia. E aqui nós podemos adicionar um novo disco, seja um disco zerado, um disco que a Microsoft vai criar para nós, ou um disco existente, que porventura foi de uma outra máquina, a gente pode adicionar aqui também. A parte das redes, pessoal, se você não tiver uma VNet, vai aparecer como está aparecendo aqui para mim agora, com default e tudo em condições de novo. Outro item legal aqui que a gente pode avaliar também é a parte onde nós vamos ter um serviço de gerenciamento e nós podemos configurar a parte de stop start dessa máquina. Olha só que interessante, ele já vem aqui marcado por padrão que ele vai desligar todo dia às 19 horas. Isso vai alterar aquela questão do custo que eu havia comentado com vocês. Essa opção de diagnóstico de inicialização, você pode deixá-la ativada ou desabilitar, e ele vai ser uma questão de monitoramento quando a máquina sobe. Aqui se eu já quiser adicionar uma extensão para essa máquina, posso clicar aqui e ver extensões. Olha só que interessante, já agente de backup, posso procurar uma extensão conhecida. Depois disso, eu posso habilitar ela para grupos de hosts, caso eu tenha grupo de reservas. E após a parte das tags, pessoal, a tag é muito importante em ambientes de produção. Nós criamos o que é conhecido como pólice para forçar ou para já determinar uma tag, mas em termos de provas E900, o que a Microsoft pode lhe perguntar é como que você vai criar uma forma de conseguir tirar o billing, ou seja, o custo da sua subscrição. Em termos práticos, você pode separar em assinaturas diferenciadas ou você pode adicionar tags a todos os recursos. É a melhor forma, a mais prática e com certeza uma das mais utilizadas no ambiente. Então, vamos voltar lá para a nossa apresentação. E o nosso próximo tópico é os serviços de aplicativo do Azure. Aqui nós temos uma plataforma totalmente gerenciada. Eu gosto de brincar que seria a hashtag paz, porque nós não temos acesso ao sistema operacional. Quando nós vamos criar um modelo de serviço de aplicativo ou um app service, se você tiver com essa plataforma em inglês, nós vamos escolher com qual plataforma que nós vamos trabalhar. E lembrando que nós não temos apenas modelos de Windows aqui, nós temos de outras plataformas também. Vamos dar uma olhadinha lá no portal como é que funciona esse modelo de criação. E voltando ao portal, vamos lá em serviços de aplicativo e vamos criar um novo serviço de aplicativo, ver quais são as configurações que determinam o nosso modelo. Primeiramente, voltamos aonde escolhemos a assinatura, precisamos associar a um grupo de recursos e aqui a gente precisa também dar um nome para o nosso aplicativo. Vou selecionar o nosso laboratório novamente, vou colocar aqui aula 02, vamos ver se está disponível esse nome. Sim, outra coisa interessante, ele permite tanto que a gente vai trabalhar com código container, onde a gente pode escolher entre Linux e Windows e também aplicativos de web estático. Vou escolher aqui um modelo de container, ele está falando aqui que vai ser um Linux, eu posso selecionar para o Windows, perceba que aqui a gente vai ter quais são as regiões que são liberadas. Se a gente vai trabalhar com código, aqui o semelhante estava lá no slide, a gente pode colocar se eu quero trabalhar em .NET, se eu quero trabalhar em Node, Java, PHP, Python, Ruby. Então aqui eu tenho uma infinidade de opções onde eu posso utilizar. Vou deixar um .NET aqui para ver qual é o modelo que ele vai trazer para nós. Já seleciono para o Windows e aqui o SKU e tamanho, isso aqui seria semelhante às famílias de máquina pessoal, porque aqui eu preciso selecionar como que vai ser o meu modelo, ele está colocando um standard S1, mas nós temos vários modelos. O que a gente precisa se recordar é que nós temos tanto o modelo de desenvolvimento e de teste, temos os modelos de produção e temos o modelo isolado. O isolado é aquele que vai ser mais caro, onde eu vou ter literalmente uma máquina para mim. Então aqui o Azure vai isolar toda a computação que eu vou estar utilizando, o recurso de computação para o meu app somente para mim. E aqui ele inclui várias features que vão ser disponibilizadas no meu ambiente. A questão de produção, nós temos aqui a família S1, aqui eu tenho outras opções mais para trás, S2, S3, cada uma delas vai diferenciar qual modelo de computação que eu vou estar utilizando. Semelhante como eu falei às famílias de máquina, mas ele tem essas três categorias, dev-teste, que é a mais em conta, mais barata, mas como o próprio nome diz, não é recomendado para o ambiente de produção. O modelo de produção, onde eu tenho várias opções aqui de recursos e o isolado para ambientes críticos e que precisam de uma alta disponibilidade e performance. A partir do momento que eu escolhi um desses modelos, o modelo escolhido vai determinar qual vai ser o acesso a recursos que eu vou ter. Por exemplo, esse modelo S1, ele não liberou para mim, por exemplo, a redundância de zona, porque ele está dizendo aqui que esse plano de serviço de aplicativo que eu estou selecionando não oferta esse modelo. E depois a gente pode configurar o modelo de monitoramento e por fim adicionar as tags para o nosso recurso. Isso na criação de um aplicativo web ou App Service. Lembrando, quando nós falamos desse modelo, estamos falando de plataforma como serviço. Vamos voltar lá para a nossa apresentação. Pessoal, no nosso próximo tópico temos os serviços de container dentro do Azure. O que acontece? O modelo de container não é um modelo novo, mas está muito difundido tanto na nuvem como também em ambientes on-premise, onde nós podemos aumentar os nossos recursos utilizando os mesmos recursos computacionais que nós já tínhamos. Ou seja, eu não preciso mais ter um servidor, subir um ambiente de virtualização como um VM ou um Hyper-V e ali criar várias máquinas virtuais e ter que administrar todas essas máquinas. Aqui nós conseguimos ter um ambiente onde ele vai fazer a requisição direto. Eu pulo essa parte, o abstraio, um modelo de virtualização e os meus containers vão estar requisitando diretamente os recursos no sistema operacional. Ela é uma oferta, digamos assim, do modelo de plataforma como serviço. E claro, quando nós temos muitos containers sendo executados, nós precisamos de um gerenciamento muito facilitado. E hoje o Kubernetes não é uma ferramenta Microsoft, que fique bem claro, mas é a ferramenta que é mais popular dentro desse contexto de administração. E a Microsoft tem a sua própria versão, que é o Azure Kubernetes, ou seja, o AKS, e ele serve para que nós venhamos conseguir administrar os nossos containers de uma maneira mais simplificada e com certeza menos dolorida, porque no dia a dia são muitas coisas que a gente precisa fazer. Então, quando nós falamos de modelo de containers, não se esqueça, estamos falando de plataforma como serviço. Outro item bastante interessante que nós temos para rever aqui também é a área de trabalho virtual do Azure, ou AVD. Esse item é bastante interessante pelo seguinte. Nós podemos ter hoje uma máquina no Azure, onde nós vamos utilizá-la como se fosse um modelo de terminal services. Ela seria uma máquina mais robusta e os usuários acessam ela, e a partir desse acesso vai ter o seu perfil e cada uma dessas pessoas vai utilizar o servidor, que seria uma máquina, mais precisamente na nuvem. Ou nós podemos ter um modelo de área de trabalho virtual, porém separada, onde todos os recursos vão ser individuais, é como se tivesse várias máquinas, uma para cada pessoa. Esse modelo é mais caro, menos utilizado, menos disponibilizado, a maioria ainda utiliza um host onde isso vai ser dividido entre as pessoas, mas é um modelo onde facilita bastante a entrega de máquinas. Está se caminhando junto com o modelo de nuvem, perceba uma empresa onde agora nós trabalhamos no modelo home office e a pessoa pode ser de outro estado, a empresa não tem condições de ficar mandando um notebook para cada um, mas ela disponibiliza uma área de trabalho virtual e a pessoa apenas utiliza o seu próprio computador de casa com acesso à internet e consegue trabalhar. E muitas vezes a empresa paga uma taxa para a pessoa utilizar o seu computador pessoal. Perceba que aqui nós temos uma abstração na questão de segurança, porque apesar de ela estar acessando uma área de trabalho virtual, isso está na nuvem, não tem nada no computador dela, então é um item bastante utilizado e tem crescido muito devido à pandemia. E os próprios serviços de rede do Azure? Pessoal, lembra que eu comentei que nós temos os mesmos features, as mesmas configurações que a gente fala no Mint on Premise, estão lá na nuvem. É claro que com nomes diferentes, alguns modelos de configuração diferenciados, mas tudo está lá e a gente precisa saber como que faz essas configurações. Então nós temos aqui um modelo de VNet, que são as redes virtuais do Azure, que nós podemos ter várias redes se comunicando entre si, vamos falar sobre o peering, quem é ele, para que ele serve. Temos também a questão do Gateway de rede privada, que seria a VPN. Lembrando que para a gente fazer um acesso do nosso datacenter para o Azure, nós podemos tanto ter uma VPN site to site, o próprio ExpressRoute, também exemplificado aqui nesse slide, e também a VPN point to site, que é aquela onde eu instalo uma aplicação na minha máquina e a partir daí eu faço a conexão com o datacenter da Microsoft. E sobre os serviços de armazenamento, a gente já tinha olhado os storage accounts, que são os armazenamentos dentro do Azure, que eles podem trabalhar tanto no modelo de blob, o Azure files, que seria os arquivos do Azure, a parte de tabelas e filas, cada um deles direcionando para um modelo diferente de utilização. E os próprios discos de armazenamento que nós podemos criar e também ter lá na nuvem disponível dentro de um container blob, inclusive isso é uma coisa que a Microsoft gosta de perguntar, qual que é o lugar indicado para que você venha guardar discos de máquinas, para que você não se esqueça, armazenamento de container blob. E a parte de arquivos do Azure é o famoso barra a barra, aquele compartilhamento que nós já tínhamos no ambiente on-premises, ele foi para a nuvem, dentro do modelo de storage account, na parte de arquivos do Azure. Sobre as camadas de armazenamento e acesso, esse é um item interessante, cai bastante em prova e vamos dar uma analisada olhando lá no portal. Vamos voltar para o portal da Microsoft e visualizar melhor como esse modelo de armazenamento funciona. Voltando ao portal, pessoal, você pode vir tanto aqui no item da busca, aqui onde tem a lupinha do lado de Microsoft Azure, ou na esquerda, mas caso não esteja aparecendo para você, você pode vir na busca, contas de armazenamento ou storage account, dependendo do idioma que tiver o seu portal, você vem em criar uma conta de armazenamento e vamos aqui para as opções que ele nos traz. Primeiramente a nossa assinatura, depois nós vamos selecionar um grupo de recursos, vou voltar a selecionar o laboratório, a conta de armazenamento, pessoal, até vou trazer aqui o mouse para pegar a informação certinho. O que você precisa saber? Primeiro, o nome do seu storage account precisa ser um nome único e ele deve ter de 3 a 24 caracteres, somente letras em caixa baixa, ou seja, letras minúsculas e números. Ele precisa ser um nome único. Isso é uma coisa bastante importante, principalmente quando você faz a criação por meio de ferramentas de automação, para garantir que vai dar tudo certo, tem que colocar algumas regrinhas ali para ele não pegar um nome já utilizado. Eu vou colocar aqui STO Valéria, vamos ver se está em utilização ou não. A princípio passou. Vou colocar aqui nessa mesma região, vou manter a Istias. Agora nós temos aqui as nossas primeiras opções entre standard e premium. O que quer dizer isso? Bom, standard ele está comentando ali que é um modelo mais utilizado para a maioria dos cenários e o premium recomendado para cenários que exigem baixa latência. Mas além disso, é importante frisar o seguinte, quando nós criamos uma conta de armazenamento, ela tem um comportamento semelhante a um resource group, que é como se você criasse uma caixa vazia. Porque após criar essa conta de armazenamento é que você vai criar um blob, você vai criar um file, uma tabela ou até mesmo uma lista de filas. Até então não tem nada criado, você está criando somente a casca, somente essa caixa vazia. Porém, quando a gente cria o storage account ou conta de armazenamento, nós precisamos escolher entre o modelo standard e o modelo premium. O que isso implica além de performance? Preço. Porque no modelo premium, por exemplo, tudo aquilo que você reservar em questão de espaço, você já vai arrancar sendo cobrado. Por exemplo, se eu disser depois que eu quero 10 gigas de espaço, eu já vou pagar por esses 10 gigas. Se eu utilizar 1 giga, eu vou pagar pelos 10 do mesmo jeito. Então isso é um ponto a ser citado. No standard não, vai ser dentro do modelo de pagamento conforme eu uso. E outra coisa interessante é o modelo de redundância. Aqui nós temos o LRS, o GRS, ZRS e o GZRS. Pessoal, esses são modelos de replicação, nós vamos falar sobre eles em outros slides também ao longo deste curso, mas o que é importante você saber já de antemão é que o LRS, o GRS e o ZRS, todos eles vão fazer cópias, porém nós temos diferenças aqui na questão de performance, porque o LRS vai fazer 3 cópias das suas informações dentro de um mesmo data center da Microsoft. Ou seja, se aquele data center cair, você perde o acesso à sua informação. O ZRS também faz 3 cópias, mas ele faz essas cópias uma em cada data center, ou seja, aqui você tem uma garantia até que a zona inteira caia. O GRS faz as 3 cópias e faz mais cópias para fora do seu data center principal, sua região principal, ou seja, você tem uma replicação de região. Então, ainda que a região primária caia, você tem acesso a esse dado na região secundária. E o GZRS vai garantir que você tenha uma solução idêntica com replicação destes recursos, só que utilizando o mesmo modelo de cópia do ZRS. Então aqui, mais adiante, nós vamos fazer um comparativo interessante bem bolado de cada uma dessas cópias, mas é importante, mais adiante, você garantir que está com conhecimento bem afiado, porque a Microsoft gosta de perguntar sobre esses modelos de cópia. E essa caixinha que está marcada aqui embaixo, para o modelo GRS, se eu trocar para o LRS, olha só, ela some, porque o modelo de LRS não tem uma réplica de leitura. Apenas se eu trazer aqui, por exemplo, para o GRS, ou se eu trazer aqui de novo para o ZRS, ela também some. Agora, se eu trago para o GZRS, eu também tenho essa opção de leitura. Esses modelos, pessoal, a gente vai ver mais adiante, mas fique ligado, isso cai bastante em prova. Outra coisa que a gente precisa ver aqui é que a gente vai trazer essa camada de acesso, ele já mostra para nós aqui a camada de acesso a quente e frio. Aqui, mas aqui não está aparecendo o modelo arquivar, é porque ele não vai aparecer aqui na conta de armazenamento nessa criação. Mas, depois, quando a gente cria um blog, a gente pode configurar os arquivos para eles irem para o modelo de arquivar ou archive, caso você esteja com o seu portal em inglês. Então, os três modelos seriam o quente, o frio e o archive. Então, a gente vai ter aqui algumas diferenças da tradução, no caso aqui nós temos como frequente, esporádico e arquivar. Mas a ideia é que a gente tenha bem em mente como que funciona esse modelo e quais são as vantagens. Vamos voltar lá para o slide e eu vou explicar direitinho como funcionam esses modelos. Vamos aqui para a nossa apresentação, eu até deixei a nomenclatura exatamente como está aparecendo lá no portal, porque as vezes a tradução da Microsoft não nos ajuda em alguns pontos. Então, entenda como o modelo frequente é o modelo quente, em português, se tiver em inglês a sua plataforma, ele vai aparecer lá como hot. O modelo esporádico é o modelo frio, ou seja, o cool, e o modelo de arquivamento é o archive. Bom pessoal, como é que a Microsoft vai nos cobrar sobre esse armazenamento, falando lá do portal nos storage accounts? Quando você salva seus arquivos no modelo quente, ou seja, o hot, a Microsoft vai lhe cobrar um valor X pelo armazenamento e vai lhe cobrar pelos acessos um valor mais baixo, porque ela entende que você está fazendo essa leitura com muita frequência, por isso que você utilizou esse modelo de armazenamento. Se você escolhe o modelo de armazenamento frio ou cool, você está dizendo o que? Microsoft, eu estou com as informações aí, mas eu vou acessar poucas vezes, tá? Não vai ser uma coisa que eu vou olhar muito, mas eu vou olhar. Então ela vai manter as suas informações lá, vai lhe cobrar menos pelo repositório, mas vai lhe cobrar mais cada vez que você for acessar, se comparado ao modelo quente. E o arquivamento, o archive, é um repositório a frio, aonde esses dados, eles, uma, eles precisam ficar lá por pelo menos 180 dias, dois, nós temos um SLA para fazer o restore dessas informações, porque ele fica em um repositório aonde a gente costuma dizer que nós precisamos reidratar os dados, ou seja, reidratar porque cada vez que você salva informações nesse repo, ele vai literalmente distribuir aonde tem espaço. Então é como se ele pegasse o seu arquivo e fizesse dele um quebra-cabeças e larga um pouco em cada lugar. Quando você diz, ô Microsoft, eu preciso de um dado que está lá no archive, ela olha assim, vixi, então tá, eu tenho meu SLA aí, vai, senta e espera, tá? E a gente tem que dizer, amém. E o que acontece? A gente já vai trazer essas informações em cima do SLA e a gente vai ter uma questão de cobrança relativo a esses dados. Quando que eu vou utilizar o archive, o arquivar, para backup? E de preferência para backups de informações que eu sei que muito, na dúvida, eu vou precisar fazer um restore e eu preciso ter essas informações lá por pelo menos 180 dias. Quando a gente fala dos dois primeiros modelos, o quente e o frio, a gente pode literalmente ficar trocando entre esses dois modelos. Até tem um comentário ali que a gente pode alternar entre essas camadas de acesso a qualquer momento. Ah, mas eu não poderia, então, trocar lá para o archive e ter acesso negativo. O archive é um ponto a mais onde a gente vai precisar dessa questão da reidratação. Perceba que tanto no acesso frequente, que é o quente, ou o frio, a gente acessa o dado ali em tempo real. A diferença é quanto isso vai me custar. Então, eu posso ficar trocando. Galera, mas eu posso criar uma regra e determinar quando uma informação vai para cada um desses lugares. E, sei lá, eu não tenho como ficar controlando, a gente tem aqui um repositório muito grande. Então, eu posso determinar que se esse arquivo ficar 180 dias sem ser acessado, ele joga para o archive. Ou se ele ficar 90 dias e ele joga para lá, sim, a gente pode. Inclusive, você pode determinar, até dentro de uma história de acounts, que se aquela informação não for acessada dentro de um sistema, você até exclui. Isso é uma coisa que você pode fazer. Mas é claro, isso vai depender do seu planejamento de negócio, de que informação a gente está falando, eu posso excluir, não posso. Mas você pode, sim, determinar por meio de regras de acesso em qual dessa camada de armazenamento as suas informações vão ficar. Então, é importante, primeiro, para a nossa prova que você saiba que elas existam, qual que é a ordem de cada uma delas, quanto que você paga por cada uma delas, não necessariamente em reais ou em dólares, mas quando que cada uma delas vai ser mais conveniente. Então, lembrando que quando a gente tem esse acesso a quente, a gente até paga um pouquinho mais pelo repositório, mas muito menos pelo acesso. Então, muitas das vezes, entre o modelo quente e o frio, o quente ainda é mais indicado, porque ainda que eu pague mais pelo repo, vai dar uma diferença se eu tiver uma questão de muitos acessos em arquivos que estão na camada fria. Preste bastante atenção, anote, revise essa parte do conteúdo, porque cai bastante lá na nossa prova. E falando sobre o nosso próximo tópico, serviços de banco de dados do Agile, nós já tínhamos visitado, principalmente, a parte de banco de dados SQL, mas lembrando que nem só de SQL vive o Agile. Nós temos também MySQL, Postgre, Cosmos DB, temos Databricks, temos Synapse, entre outros. E eu preciso saber o nome de todo mundo, o que eles fazem? De alguns deles, sim, seria bastante importante para essa prova. Primeiramente, serviço de banco de dados, plataforma como serviço. No Azure Cosmos Database, ele é um serviço de dados distribuído globalmente, isso é importante a gente falar, e ele tem várias APIs. O que seria API? É que ele comunica e também garante uma entrega com vários modelos de banco de dados. Quando a gente fala do SQL, do Azure, não pense que a gente consegue apenas criar o banco de dados também no modelo de plataforma como serviço. Mas a gente pode, caso necessário, criar uma máquina e instalar o banco de dados do Azure. O que a gente precisa saber é que se a gente fizer nesse modelo de infraestrutura como serviço, você é responsável por praticamente tudo. Quando nós criamos um banco de dados dentro do Azure, aqui nós temos uma diferença, porque nós estamos utilizando um modelo de plataforma, muitas coisas aqui vão ser automatizadas pelo Azure, não vai ser nossa responsabilidade. Lembra daquela nossa tabelinha de responsabilidade que nós vimos na aula passada. A parte também do banco de dados do Azure para MySQL e Postgre, é interessante a gente saber, porque nós temos dentro desse modelo um banco de dados gerenciado, seja ele para desenvolvedores ou seja de open source. Então é importante a gente avaliar aqui essa questão de só porque está no Azure não quer dizer que seja coisa da Microsoft. Nós temos vários modelos de banco de dados dentro do Azure e a gente precisa avaliar qual deles é o mais indicado para o nosso tipo de serviço. Sobre a instância gerenciada, pessoal, reforçando, quando nós estamos fazendo um modelo de migração para o Azure, uma instância gerenciada ela vai permitir que a gente faça, aqui ele está utilizando a palavra lift and shift, mas a gente também chama isso de as-is ou migra assim como está. Porque o que acontece, quando nós temos um SQL na nossa empresa, a gente quer fazer essa migração para a nuvem, nós podemos levar todos esses dados diretamente para a plataforma como serviço. Mas é importante eu colocar um adendo aqui a nível de informação também, que o que é 100% compatível de um banco de dados do SQL quando você vai levar para a nuvem, ainda é subir uma máquina e instalar o SQL. Se tiver na sua prova alguma coisa desse tipo, quem faz as trilhas da DP900 já deve ter visto esse tipo de questão. Se for 100% sem fazer alteração nenhuma, garantir total compatibilidade, a gente ainda vai manter o modelo de infraestrutura como serviço. Mas eu posso também fazer uma migração lift and shift, como a gente está vendo aqui, aonde eu vou pegar os dados do meu banco e vou levar para a nuvem no modelo de plataforma como serviço. Funciona também? Funciona. Mas se eu tiver muita coisa de legado, muita coisa que eu não consegui mapear, que eu não tive tempo de olhar, o mais indicado ainda é subir uma máquina lá no Azure e depois de estar lá a gente consegue fazer essa migração também. Lembrando, modelo de instância gerenciada, hashtag paz, e eu vou ter muito menos coisa para fazer porque a Microsoft tem que botar a mão aqui em algumas coisas, tipo backup, validação, e eu consigo também trazer a licença existente lá de dentro de casa, literalmente, meu ambiente on-premises, e assim eu diminuo o custo. Semelhante foi ali naquela tela quando a gente estava fazendo a criação da máquina, perguntava ali, você tem uma licença, isso vai diminuir até 49% do preço. Então falando de instância gerenciada, sim, ela é a melhor opção porque ela vai diminuir o meu esforço operacional, falando de dia a dia, mas se eu quiser 100% de compatibilidade, eu ainda vou ter que escolher um modelo de infraestrutura como serviço. Mas se eu tiver tempo para mapear todos os requisitos e tudo mais, eu já consigo trazer ela no modelo de plataforma como serviço. Pessoal, chegamos ao final da nossa segunda aula, eu espero que você tenha gostado. Vamos agora para o nosso teste de conhecimento, avaliar se você está com os conhecimentos em dia sobre essa parte do conteúdo e garantir o seu pé no teste. Então vamos à nossa primeira pergunta. Ao planejar migrar um site público para o Azure, você deve, alternativa A, se planejar para pagar os custos mensais de uso, alternativa B, pagar para transferir todos os dados do site para o Azure, alternativa C, implantar uma VPN ou alternativa D, reduzir o número de conexões com o site. Pessoal, se nós temos um site público e nós estamos migrando para o Azure, então o que nós precisamos fazer é planejar para pagar os custos mensais. Agora nós estamos trazendo a nossa página, o nosso site, para dentro de um ambiente de nuvem pública, aqui a gente vai pagar conforme o uso mensalmente. Segunda pergunta, qual serviço fornece computação sem servidor no Azure? Aqui a gente tem muita pessoa que fica com dúvida, eu gosto muito dessa questão porque ela costuma cair em prova, então tome nota. Alternativa A, máquinas virtuais do Azure, alternativa B, funções do Azure, alternativa C, conta de armazenamento ou alternativa D, hosts dedicados. Aqui o pessoal geralmente fica em dúvida, mas a resposta certa é funções do Azure. Pessoal, conta de armazenamento, ela aparece como infraestrutura, como serviço, ela não fornece plataforma como serviço, hosts dedicados e máquinas virtuais, a gente já sabe que é infraestrutura como serviço, meio que por intuição. Então aqui a resposta certa é letra B. Próxima pergunta, sua empresa planeja migrar para o Azure? A empresa tem vários departamentos, todos os recursos do Azure usados por cada departamento serão gerenciados por um administrador de departamento. Quais são as duas técnicas possíveis para segmentar o Azure para os departamentos? Aqui aquela questão que eu tinha comentado com vocês sobre como que a gente consegue dividir em questão de custos e recursos. Aqui nós estamos falando sobre gerenciamento, então tem uma certa semelhança em um ponto e outro ponto a gente tem que identificar. Mas como que eu vou conseguir segmentar? Em questão de permissionamento, eu posso tanto utilizar como assinaturas, como grupos de recursos. Aqui eu vou direcionar o permissionamento para quem eu preciso. Próxima pergunta, você tem um aplicativo web do Azure, você precisa gerenciar as configurações do aplicativo da web a partir de um iPhone. Quais são as duas ferramentas de gerenciamento que você pode usar? Então a partir de um iPhone, o que eu consigo fazer? Bom, primeiramente nós sabemos que conseguimos usar o Cloud Shell, porque o Cloud Shell é aberto a partir do portal do Azure. Então você consegue abrir o portal no iPhone e se você quiser utilizar alguma coisa pelo Cloud Shell, consegue também. Ah, mas não vai ser muito simpático? Provavelmente vai ser um pouco sofrido a gente utilizar dessa forma, mas a gente sabe que dá para fazer. Próxima pergunta, você precisa identificar o tipo de falha para qual uma zona de disponibilidade do Azure pode ser usada para proteger o acesso aos serviços. O que você deve identificar? Uma falha na região, uma falha do data center, uma falha de armazenamento ou uma falha do servidor físico? Pessoal, falha de zona de disponibilidade, o que eu posso usar para proteger? Bom, aqui eu tenho que utilizar uma falha do data center, porque cada data center representa uma zona de disponibilidade. Então quando eu quero mais disponibilidade, eu replico isso entre as zonas. Se eu quisesse uma alta disponibilidade entre essas zonas, eu ia precisar de uma disponibilidade através da minha região. Então para cada tipo de falha de uma zona de disponibilidade, eu estou falando da falha de um data center. Próxima pergunta, quando você precisa delegar permissões para várias máquinas virtuais do Azure simultaneamente, você deve implantar a letra A para o mesmo grupo de recursos, letra B usando o mesmo modelo do Azure Resource Manager ou letra C para a mesma zona de disponibilidade ou máquinas virtuais do Azure para a mesma região? Bom, se eu quiser delegar permissões para várias máquinas simultaneamente, eu vou colocar elas no mesmo grupo de recursos, atribuo a permissão lá no grupo de recursos e elas vão herdar em todo grupo essas permissões. Então isso é importante de lembrar, a questão de permissão ela vai ser herdada se eu atribuo lá dentro do grupo de recursos. Mas utilizar o mesmo modelo não vai funcionar, a mesma zona de disponibilidade ou as máquinas na mesma região também não funcionam. E chegamos ao final de mais uma aula do nosso conteúdo AZ-900. Pessoal, eu espero que esse conteúdo tenha sido de grande valia para você. Em breve o nosso próximo vídeo. Nos siga nas redes sociais e até o nosso próximo encontro. Até lá!\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
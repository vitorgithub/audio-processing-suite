{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX5uP_7nxtCp",
        "outputId": "278f5602-58e2-4f53-86d6-80187f6f1bcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20230918)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.1.0)\n",
            "Requirement already satisfied: tiktoken==0.3.3 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.3.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper) (2.31.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.27.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.12.4)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (17.0.3)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.91)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper) (0.41.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n",
            "Requirement already satisfied: ffmpeg in /usr/local/lib/python3.10/dist-packages (1.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai-whisper --no-cache-dir\n",
        "!pip install pydub\n",
        "!pip install psutil\n",
        "!pip install ffmpeg\n",
        "\n",
        "import os\n",
        "import whisper\n",
        "import gc\n",
        "from pydub import AudioSegment\n",
        "import tempfile\n",
        "from tqdm.notebook import tqdm\n",
        "import psutil\n",
        "import time  # Precisamos importar o módulo 'time' para usar 'time.sleep()'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_audio(file_name, chunk_length_ms=300000):\n",
        "    audio = AudioSegment.from_file(file_name, format=\"mp3\")\n",
        "    return [audio[i:i+chunk_length_ms] for i in range(0, len(audio), chunk_length_ms)]\n",
        "\n",
        "def split_and_transcribe_audio(model, file_name, output_file, chunk_length_ms=300000):\n",
        "    chunks = split_audio(file_name, chunk_length_ms)\n",
        "    with open(output_file, 'w', encoding='utf-8') as f_out:\n",
        "        for chunk_num, audio_chunk in enumerate(chunks):\n",
        "            temp_file = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
        "            try:\n",
        "                audio_chunk.export(temp_file.name, format=\"wav\")\n",
        "                retry_attempts = 3\n",
        "                delay = 2  # delay inicial em segundos\n",
        "                success = False\n",
        "                while retry_attempts > 0:\n",
        "                    try:\n",
        "                        result = model.transcribe(temp_file.name, language=\"Portuguese\")\n",
        "                        f_out.write(result[\"text\"])\n",
        "                        success = True\n",
        "                        break\n",
        "                    except MemoryError:\n",
        "                        print(f\"Erro de memória no chunk {chunk_num}. Tentando novamente em {delay} segundos...\")\n",
        "                        retry_attempts -= 1\n",
        "                        time.sleep(delay)\n",
        "                        delay *= 2  # Double the delay for the next retry\n",
        "                    except Exception as e:\n",
        "                        print(f\"Erro no chunk {chunk_num}: {e}\")\n",
        "                        break\n",
        "\n",
        "                if not success:\n",
        "                    print(f\"Não foi possível transcrever o chunk {chunk_num} após várias tentativas.\")\n",
        "\n",
        "                if chunk_num % 20 == 0 and chunk_num > 0:\n",
        "                    gc.collect()\n",
        "                    mem = psutil.virtual_memory()\n",
        "                    while mem.available < 1 * (1024 ** 3):  # espera até ter pelo menos 1GB disponível\n",
        "                        print(f\"Memória baixa ({mem.available / (1024.0 ** 3):.2f} GB). Esperando...\")\n",
        "                        time.sleep(10)\n",
        "                        mem = psutil.virtual_memory()\n",
        "\n",
        "            finally:\n",
        "                temp_file.close()\n",
        "                os.unlink(temp_file.name)\n",
        "\n",
        "def main():\n",
        "    model = whisper.load_model(\"large\")\n",
        "    files = [\n",
        "        \"./sample_data/audio-mic.mp3\",]\n",
        "\n",
        "\n",
        "\n",
        "    for file_path in files:\n",
        "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
        "        output_file = os.path.join(\"./sample_data\", f\"{base_name}.txt\")\n",
        "        split_and_transcribe_audio(model, file_path, output_file)\n",
        "        print(f\"Transcrição para o arquivo '{file_path}' salva em '{output_file}'.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfIXGXk2x3Pn",
        "outputId": "58c74112-62d6-4617-d1e5-3e6132622a3e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 2.87G/2.87G [00:18<00:00, 163MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcrição para o arquivo './sample_data/audio-mic.mp3' salva em './sample_data/audio-mic.txt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "def compactar_arquivos_transcricao(diretorio, nome_zip_saida):\n",
        "    \"\"\"\n",
        "    Compacta todos os arquivos .txt em um diretório específico em um arquivo zip.\n",
        "\n",
        "    Args:\n",
        "    - diretorio (str): O diretório de onde os arquivos .txt serão coletados.\n",
        "    - nome_zip_saida (str): O nome do arquivo zip de saída.\n",
        "    \"\"\"\n",
        "    with zipfile.ZipFile(nome_zip_saida, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, _, files in os.walk(diretorio):\n",
        "            for file in files:\n",
        "                if file.endswith(\".txt\"):\n",
        "                    file_path = os.path.join(root, file)\n",
        "                    arcname = os.path.relpath(file_path, diretorio)\n",
        "                    zipf.write(file_path, arcname)\n",
        "\n",
        "def main():\n",
        "    diretorio = \"./sample_data/sections\"  # Diretório onde estão os arquivos de transcrição\n",
        "    nome_zip_saida = \"transcricoes_audios.zip\"  # Nome do arquivo zip de saída\n",
        "\n",
        "    compactar_arquivos_transcricao(diretorio, nome_zip_saida)\n",
        "    print(f\"Arquivos de transcrição foram compactados em '{nome_zip_saida}'.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "wZiKX_tu263Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}